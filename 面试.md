### JAVA基础

#### default关键字

`default` 这个关键字很特殊，既属于程序控制，也属于类，方法和变量修饰符，还属于访问控制。

- 在程序控制中，当在 `switch` 中匹配不到任何情况时，可以使用 `default` 来编写默认匹配的情况。
- 在接口中，从 JDK8 开始引入了默认方法，可以使用 `default` 关键字来定义一个方法的默认实现。
- 在访问控制中，如果一个方法/成员变量前没有任何修饰符，则默认会有一个修饰符 `default`。

#### protected访问修饰符

protected修饰符给出的大部分定义解释都为 **protected修饰的成员（下文中的成员统一指代属性和方法），允许同包下的类和不同包的子类访问。**

#### 重载与重写的区别：

- 重载就是同样的一个方法能够根据输入数据的不同，做出不同的处理。方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同。（编译时就确定）

- 重写就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，你就要覆盖父类方法
  
  1. 方法名、参数列表必须相同，子类方法返回值类型应比父类方法返回值类型更小或相等，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类。
  
  2. 如果父类方法访问修饰符为 `private/final/static` 则子类就不能重写该方法，但是被 `static` 修饰的方法能够被再次声明（但是一定要声明为static方法）。（这里需要说明一下：父类的private方法子类无法访问到，自然不属于重写的范畴，但是你可以写一个一样的方法；被final修饰的方法不能重写，编译无法通过）
  
  3. 构造方法无法被重写。

#### 可变长参数方法与重载的固定参数方法优先级：

固定参数方法会有更高的优先级，即如果有满足的固定参数方法，会先执行这个。

#### 基本类型和包装类型的区别？

- 默认值：成员变量包装类型不赋值就是 `null` ，而基本类型有默认值且不是 `null`。
- 类型不同：一种是JAVA对象，一种是基本类型。所以包装类型可用于泛型，而基本类型不可以。
- 存放位置：基本数据类型的**局部变量**存放在JVM的局部变量表中，基本数据类型的成员变量（未被 `static` 修饰 ）存放在 Java 虚拟机的堆中。而包装类型属于对象类型，我们知道几乎所有对象实例都存在于堆中。
- 相比于对象类型， 基本数据类型占用的空间非常小。

#### 包装类型的缓存机制了解么？

Java 基本数据类型的包装类型的大部分都用到了缓存机制来**提升性能**。

`Byte`,`Short`,`Integer`,`Long` 这 4 种包装类默认创建了数值 **[-128，127]** 的相应类型的缓存数据，`Character` 创建了数值在 **[0,127]** 范围的缓存数据，`Boolean` 直接返回 `True` or `False`。

**Integer 缓存源码：**

```
public static Integer valueOf(int i) {
    if (i >= IntegerCache.low && i <= IntegerCache.high)
        return IntegerCache.cache[i + (-IntegerCache.low)];
    return new Integer(i);
}
private static class IntegerCache {
    static final int low = -128;
    static final int high;
    static {
        // high value may be configured by property
        int h = 127;
    }
}
```

**`Character` 缓存源码:**

```
public static Character valueOf(char c) {
    if (c <= 127) { // must cache
      return CharacterCache.cache[(int)c];
    }
    return new Character(c);
}

private static class CharacterCache {
    private CharacterCache(){}
    static final Character cache[] = new Character[127 + 1];
    static {
        for (int i = 0; i < cache.length; i++)
            cache[i] = new Character((char)i);
    }

}
```

**`Boolean` 缓存源码：**

```
public static Boolean valueOf(boolean b) {
    return (b ? TRUE : FALSE);
}
```

两种浮点数类型的包装类 `Float`,`Double` 并没有实现缓存机制。

使用new 创建包装对象不会用到缓存。

#### 面向对象三大特点

##### 封装

封装是指把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。然后外界对对象属性的访问则通过方法给出。这样做可以控制外部对象对内部属性的访问与修改。

##### 继承

继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能。继承可以提高代码重用与程序的可维护性，提高开发效率。

##### 多态

表示一个对象具有多种的状态，**具体表现为父类的引用指向子类的实例**。

#### 接口和抽象类有什么共同点和区别？

**共同点** ：

- 都不能被实例化。
- 都可以包含抽象方法。
- 都可以有默认实现的方法（Java 8 可以用 `default` 关键字在接口中定义默认方法）。

**区别** ：

- 接口主要用于对类的行为进行约束，以及用于接口回调。抽象类主要用于代码复用，强调的是所属关系。
- 一个类只能继承一个类，但是可以实现多个接口。
- **接口中的成员变量只能是 `public static final` 类型的，不能被修改且必须有初始值，而抽象类的成员变量默认 default，可在子类中被重新定义，也可被重新赋值。**

#### 深拷贝、浅拷贝、引用拷贝

- **浅拷贝**：浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同一个内部对象。
- **深拷贝** ：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。
- **引用拷贝**：只是将对象的引用（即对象的地址）复制一份。

#### 为什么String对象不可变

内部的char数组是private修饰的且没有提供任何修改该数组的方法给外界，而String类也被final修饰不可继承

#### 字符串常量池

JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。

#### 异常

##### Exception 和 Error 有什么区别？

是Throwable的两个子类

- **`Exception`** :程序本身可以处理的异常，可以通过 `catch` 来进行捕获。`Exception` 又可以分为 Checked Exception (受检查异常，必须处理) 和 Unchecked Exception (运行时异常的子类 不受检查异常，可以不处理)。
- **`Error`** ：`Error` 属于程序无法处理的错误 ，不建议通过`catch`捕获 。例如 Java 虚拟机运行错误（`Virtual MachineError`）、虚拟机内存不够错误(`OutOfMemoryError`)、类定义错误（`NoClassDefFoundError`）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止。

#### IO流的概念

数据输入到计算机内存的过程为输入，输出到外部存储的过程称为输出。

在Java中，输入流域输出流都分为字节流与字符流

InputStream/OutputStream/Reader/Writer(抽象类)

##### IO流的filter模式

各种InputStream具有各自的特点，如果想要有多个流的特点，则可以通过组合的方式获取，比如

`InputStream in = new BufferedInputStream(new FileInputStream("input.txt"));`

这样，in就获得了从文件获得输入流和缓冲流的特点，非常方便，并且无论我们包装多少次，得到的对象始终是`InputStream`，我们直接用`InputStream`来引用它，就可以正常读取

##### JAVA 常见 IO模型

###### BIO

​    阻塞IO，发起read系统调用后，阻塞直到内核拷贝数据到用户空间

###### 同步非阻塞IO：

应用程序不阻塞，不断轮询发起read调用，直到准备好数据。    

###### IO多路复用

IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -> 用户空间）还是阻塞的。

IO多路复用模型可以减少许多无效的系统调用，减少了对CPU资源的消耗。

NIO ，有一个非常重要的**选择器 ( Selector )** 的概念，也可以被称为 **多路复用器**。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会通知应用程序为其服务。

涉及到的系统调用select、poll、epoll（性能更好）

###### AIO

应用程序发起read后做自己的事去了，内核准备好数据后，执行回调通知应用程序。

#### NIO

有必要深入说一下JAVA的NIO框架

##### buffer

缓存区是一个在内存中的数组，并且提供了数据的读取、添加等操作。他是NIO的基石。

对于每个基本数据类型，都有一个对于的缓冲区抽象类，而且buffer不仅可以在堆中分配内存，还能在直接内存中分配内存。

###### 几个重要成员变量以及含义

1. position 表示下一个被读或者写的位置
2. capacity 表示数组大小
3. limit 表示这个缓冲区读或者写的最大位置
4. Mark 表示调用reset之后，position的新位置，默认-1
5. offset 表示偏移量，在get于put中会与pos相加（Buffer类没有，子类里有）
6. address 供直接内存缓冲使用，存放数组地址

###### 读缓冲

1. get(index) 读取某个位置的数据，不会更更新position
2. get() 读取pos位置的数据，pos+1
3. get([]arr,int offset,length)从缓存中读取len个数字到数组中 pos会变化

###### 写缓冲

1. put(val) 写入数据，更新pos
2. Put(index,val) 在指定位置写入数据，不更新pos
3. put([]arr,offset,len)往缓存中写入len个数据，更新pos

###### 其他操作简介

- `public abstract IntBuffer compact()`  -  压缩缓冲区，将未使用过的数据（pos-limit之间）移动到头部，然后把pos更新为下一个位置

- `public IntBuffer duplicate()`  -  复制缓冲区，会直接创建一个新的数据相同的Buffer，但是共用底层数组

- `public abstract IntBuffer slice()`  -   划分缓冲区；这个划分的意思是，将当前的pos设置成新Buffer的offset。底层共用数组

- `public final Buffer rewind()`  -  重绕缓冲区，其实就是把position归零，然后mark变回-1

- `public final Buffer clear()`  -  将缓冲区清空，所有的变量变回最初的状态

- `public final Buffer flip()` - 翻转缓冲区，即limit = pos pos = 0 mark = -1

###### DirectXXBuffer

用直接内存创建的缓冲区，直接内存不受JVM管理，所以内存的释放与申请都是调用Unsafe包下的方法。

**几个重要的参数：**

- att 这个对象的作用是在两个buffer对象共用一个顶层数组时，如果一个Buffer没有被引用，那么它会被Cleaner清理内存，这是不行的。所以在调用那些共用数组的方法后，把原来的Buffer对象赋值给att
- cleaner 是一个Cleaner对象，继承自虚引用，当Buffer不被任何强引用指向时，会触发cleaner的clean方法，调用一个内部类清理直接内存

##### Channel

在传统IO中，我们都是通过流进行传输，数据会源源不断从流中传出；而在NIO中，数据是放在缓冲区中进行管理，再使用通道将缓冲区中的数据传输到目的地。而buffer就是配合channel一起使用的

###### channel的层次结构

channel的根接口时Channel，继承Closeable接口，定义了两个方法isOpen()与close() 其子接口有可读Channel、可写Channel、以及两个操作都可以的Channel，总之，不同的Channel都有各自的功能

###### channel的基本操作

```java
public static void main(String[] args) throws IOException {
    /*
      通过RandomAccessFile进行创建，注意后面的mode有几种：
      r        以只读的方式使用
      rw   读操作和写操作都可以
      rws  每当进行写操作，同步的刷新到磁盘，刷新内容和元数据
      rwd  每当进行写操作，同步的刷新到磁盘，刷新内容
     */
    try(RandomAccessFile f = new RandomAccessFile("test.txt", "rw");  //这里设定为支持读写，这样创建的通道才能具有这些功能
        FileChannel channel = f.getChannel()){   //通过RandomAccessFile创建一个通道
        channel.write(ByteBuffer.wrap("伞兵二号马飞飞准备就绪！".getBytes()));

        System.out.println("写操作完成之后文件访问位置："+channel.position());  //注意读取也是从现在的位置开始
        channel.position(0);  //需要将位置变回到最前面，这样下面才能从文件的最开始进行读取

        ByteBuffer buffer = ByteBuffer.allocate(128);
        channel.read(buffer);
        buffer.flip();

        System.out.println(new String(buffer.array(), 0, buffer.remaining()));
    }
}
```

##### FileLock

我们可以创建一个跨进程文件锁来防止多个进程之间的文件争抢操作（注意这里是进程，不是线程）FileLock是文件锁，它能保证同一时间只有一个进程（程序）能够修改它，或者都只可以读，这样就解决了多进程间的同步文件，保证了安全性。但是需要注意的是，它进程级别的，不是线程级别的，他可以解决多个进程并发访问同一个文件的问题，但是它不适用于控制同一个进程中多个线程对一个文件的访问。

```java
public static void main(String[] args) throws IOException, InterruptedException {
      //创建RandomAccessFile对象，并拿到Channel
    RandomAccessFile f = new RandomAccessFile("test.txt", "rw");
    FileChannel channel = f.getChannel();
    System.out.println(new Date() + " 正在尝试获取文件锁...");
      //接着我们直接使用lock方法进行加锁操作（如果其他进程已经加锁，那么会一直阻塞在这里）
      //加锁操作支持对文件的某一段进行加锁，比如这里就是从0开始后的6个字节加锁，false代表这是一把独占锁
      //范围锁甚至可以提前加到一个还未写入的位置上
    FileLock lock = channel.lock(0, 6, false);
    System.out.println(new Date() + " 已获取到文件锁！");
    Thread.sleep(5000);   //假设要处理5秒钟
    System.out.println(new Date() + " 操作完毕，释放文件锁！");

      //操作完成之后使用release方法进行锁释放
    lock.release();
}
```

##### IO多路复用 Selector

IO多路复用是一种非阻塞的IO，在传统的IO网络通讯中，如果server一直接收不到连接，会一直卡在那里（在同一时刻指只会有一个连接建立），同时，处理一个连接，需要新建一个线程处理，但是很多时候这个连接不会一直发消息，可能发了一会消息之后就不发了，但是这个线程仍然会阻塞在这里等待客户端的消息，这是很消耗性能的，如果有非常多的请求，则会有大量线程被创建。

选择器是当具体有某一个状态（比如读、写、请求）已经就绪时，才会进行处理，而不是让我们的程序主动地进行等待。也就是说，我们只有在连接的某一个状态就绪时，才会去处理请求。即我们通过一个SELECTOR去发现要处理的请求，进而让程序去处理，这就是IO多路复用。

selector的实现方案：

- **select**：当这些连接出现具体的某个状态时，只是知道已经就绪了，但是不知道详具体是哪一个连接已经就绪，每次调用都进行线性遍历所有连接，时间复杂度为`O(n)`，并且存在最大连接数限制。

- **poll**：同上，但是由于底层采用链表，所以没有最大连接数限制。

- **epoll**：采用事件通知方式，当某个连接就绪，能够直接进行精准通知（这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的，只要就绪会会直接回调callback函数，实现精准通知，但是只有Linux支持这种方式），时间复杂度`O(1)`，Java在Linux环境下正是采用的这种模式进行实现的。

Reactor模式-更加标准的io多路复用网络通信

![](/Users/renchan/Library/Application%20Support/marktext/images/2022-12-06-23-14-05-image.png)

解释：由一个Reactor去处理收到的ACCEPT请求，在获取到ACCEPT请求后，Acceptor的run方法调用，从Reactor线程池中轮询一个Reactor的Selector，把这个channel注册到这个selector上，并监听read事件

#### Netty

netty是对NIO包进行的封装与改进，并解决了NIO包的一些问题，性能也更好。

##### ByteBuf

netty自己实现的缓冲区，与Buffer的区别在于其使用了读写指针，同时工作，且支持动态扩容。而且支持池化缓冲区，减少内存的申请（尤其是针对直接内存）

##### Netty工作模型

- Netty 抽象出两组**线程池**BossGroup和WorkerGroup，BossGroup专门负责接受客户端的连接, WorkerGroup专门负责读写。

- 无论是BossGroup还是WorkerGroup，都是使用EventLoop（事件循环，不断地进行事件通知）来进行事件监听的，整个Netty也是使用事件驱动来运作的，比如当客户端已经准备好读写、连接建立时，都会进行事件通知，就好像是之前的selector+reactor，只不过这里换成EventLoop了而已，它已经帮助我们封装好了一些常用操作，而且我们可以自己添加一些额外的任务（handler），如果有多个EventLoop，会存放在EventLoopGroup中，EventLoopGroup就是BossGroup和WorkerGroup的具体实现。

- 在BossGroup之后，会正常将SocketChannel绑定到WorkerGroup中的其中一个EventLoop上，进行后续的读写操作监听。

##### channel

netty的channel有更加丰富的功能，且所以的IO操作、连接建立都是异步的，返回一个ChannelFuture或者Promise对象

###### ChannelHandler

对管道中的数据进行处理操作，接口定义的方法会在特定时候调用。（比如说read时、write时等等、触发异常时）

ChannelHandler可以组成一条流水线，接在一个channel上，触发操作时依次调用（入站操作顺序，出站操作逆序）

##### 编码器与解码器

相当于是过滤器，可以对入站和出站的数据进行一些处理（比如字符串编解码、还有http请求的处理），也是一种ChannelHandler.

粘包等问题也可以用编码器来解决。

#### 什么是泛型？有什么作用？

**Java 泛型（Generics）** 是 JDK 5 中引入的一个新特性。使用泛型参数，可以增强代码的可读性以及稳定性，同时也能增强代码复用与便利（比如List设计）

编译器可以对泛型参数进行检测，并且通过泛型参数可以指定传入的对象类型。

JAVA中的泛型是类型擦除式泛型，在生成字节码后，所有的泛型都变成原来的裸类型，只是在相应的地方插入了强制类型转换（但是class文件中还是存有泛型的元信息的）。JAVA的泛型只支持对象类型，对于基本类型，必须要进行拆箱与装箱

#### 泛型的使用方式

1. 泛型类/泛型接口（静态方法无法使用类上的泛型）

```java
public interface MSst<T> {
    T get1();
}
class D3<T> implements MSst<T>{

    @Override
    public T get1() {
        return null;
    }
}
class D5<T> implements MSst<String>{

    @Override
    public String get1() {
        return null;
    }
}
class Sat<K,V>{

    public static <T> void get(){}

}
```

2. 泛型方法：

```java
    public <T> V get1(T s){
        V o = null;
        return o;
    }; 
```

#### 反射是什么

反射指通过获取类的Class对象，在运行时分析类、获取或修改调用类中属性方法等、创建新的对象。

```java
public class Ch {
    public static void main(String[] args) throws IOException, ClassNotFoundException, NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException {
        Class<Student> student = Student.class;
        // 全类名
        System.out.println(student.getName());
        // 创建一个新对象
        Student student1 = student.getConstructor(int.class,String.class).newInstance(21,"123");
        System.out.println(student1);
        // 获取类上的注解 的值
        Resource annotation = student.getAnnotation(Resource.class);
        System.out.println(annotation.name());
        // 获取成员变量的值 / 设置成员变量的值
        for (Field field : student.getDeclaredFields()) {
            field.setAccessible(true);
            if (field.getName().equals("age")){
                field.set(student1,22);
            }
        }
        for (Method declaredMethod : student.getDeclaredMethods()) {
            declaredMethod.setAccessible(true);
            if (declaredMethod.getName().equals("get"))
                declaredMethod.invoke(student1);
        }
        System.out.println(student1.getAge());

        //获取成员变量的注解的值
        for (Field field : student.getDeclaredFields()) {
            field.setAccessible(true);
            if (field.getAnnotations().length == 1){
                Resource annotation1 = field.getAnnotation(Resource.class);
                System.out.println(annotation1.name());
            }
        }
    }
}
```

#### 注解是什么

注解可以看做是一种特殊的注释，它可以定义在任何地方比如方法上类上参数上注解上等等，它可以为编译器提供元数据，也可以让程序运行时通过反射获取，从而获得元数据，这也是一些框架的做法。

元注解是作用于注解的注解，表明这个注解的属性。

注解可以有成员变量，声明方式是`类型 名称() default 值`

#### Unsafe包

`Unsafe` 是位于 `sun.misc` 包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升 Java 运行效率、增强 Java 语言底层资源操作能力方面起到了很大的作用。但由于 `Unsafe` 类使 Java 语言拥有了类似 C 语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。

Unsafe包的主要功能有：内存操作、内存屏障、对象操作、CAS、线程调度、系统信息等

#### SPI

服务提供方接口，即系统定义一套接口规范，但是具体的实现交给真正的服务提供者来实现，常见场景是数据库驱动接口，日志接口等。

使用SPI机制可以大大提高接口设计的灵活性，也方便更换服务实现方式.

#### 什么是序列化

如果我们需要持久化 Java 对象比如将 Java 对象保存在文件中，或者在网络传输 Java 对象，这些场景都需要用到序列化。

也就是说序列化是为了将java对象保存本地或者在网络上传输，将其转化为二进制字节流的过程。

反序列化是将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程

注意：transient可以让某些成员属性不序列化，但是`static` 变量因为不属于任何对象(Object)，所以无论有没有 `transient` 关键字修饰，均不会被序列化。

序列化反序列化用到的两个流（ObjectOutputStream与ObjectInputStream）

通过在类中定义writeObject与readObject可以自定义序列化 ，或者实现externalSerializable接口

如果类中有其他未序列化的成员变量，则无法序列化

```java
class Student implements Serializable {
    @Override
    public String toString() {
        return "Student{" +
                "age=" + age +
                ", name='" + name + '\'' +
                '}';
    }
    private int age;
    private String name;
    public Student(int age,String name){
        this.age = age;
        this.name = name;
    }
    private void writeObject(ObjectOutputStream out) throws IOException {
        out.writeObject(name);
        out.writeInt(age);
    }
    private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
        String o = (String)in.readObject();
        this.age = in.readInt();
        this.name = o;

    }

}
```

#### 以下语句输出什么结果？

```
System.out.println(2+2+"abc"+1+1);   // 4abc11   只要有字符串，则会自动转为字符串
```

#### JAVA8新特性

- Interface & functional Interface
- Lambda
- Stream
- Optional
- Date time-api

#### Java集合概述

java的集合类一般是指实现了Collections接口和Map接口的各种数据结构、用于存放数据的容器。使用集合可以让我们便于存放、处理各种不同的数据，提高开发效率。

常用的比如说各种List Set Queue 还有HashMap等等

#### 说说 List, Set, Queue, Map 四者的区别？

- `List`: 存储的元素是有序的、可重复的。
- `Set`: 存储的元素是无序的、不可重复的。
- `Queue`: 按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。
- `Map`: 使用键值对（key-value）存储数据，适合与快速根据key查找value
- `Deque`: 双端队列，同时还有栈的功能

#### comparable 和 Comparator 的区别

这两个接口都可以实现集合中元素的比较，Comparable接口将比较代码嵌入自身类中，而Comparator既可以嵌入到自身类中，也可以在一个独立的类中实现比较。

很多JAVA的类都已经实现了comparable 接口，可以直接进行比较，而有些自定义类的List序列，当这个对象不支持自比较或者自比较函数不能满足你的要求时，你可以写一个[比较器](https://so.csdn.net/so/search?q=比较器&spm=1001.2101.3001.7020)来完成两个对象之间大小的比较

Comparator 将算法与数据分离开来，在类没有实现comparable接口的情况下可以用比较器在不改变类的前提下进行比较。

#### 比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同

- `HashSet`、`LinkedHashSet` 和 `TreeSet` 都是 `Set` 接口的实现类，都能保证元素唯一，并且都不是线程安全的。
- `HashSet` 的底层数据结构是哈希表（基于 `HashMap` 实现）。LinkedHashSet 继承自HashSet,但是元素的插入和取出顺序满足 FIFO（通过hashSet的一个构造函数，将成员变量hashMap初始化为linkedHashMap，从而维护一个双向链表）。`TreeSet` 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。
- 底层数据结构不同又导致这三者的应用场景不同。`HashSet` 用于不需要保证元素插入和取出顺序的场景，`LinkedHashSet` 用于保证元素的插入和取出顺序满足 FIFO 的场景，`TreeSet` 用于支持对元素自定义排序规则的场景。

#### 说一说 PriorityQueue

与 `Queue` 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。

- `PriorityQueue` 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据
- `PriorityQueue` 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。
- `PriorityQueue` 是非线程安全的，且不支持存储 `NULL` 和 `non-comparable` 的对象。
- `PriorityQueue` 默认是小顶堆，但可以接收一个 `Comparator` 作为构造参数，从而来自定义元素优先级的先后。

一点注意：

```
        // 不实现comparable接口且没有实现comparable无法使用会抛出异常
        // 如果在构造时传入Comparator 则可以使用
        // 并且会优先使用Comparator
        // 大部分集合类都适用
```

#### 函数式接口

函数式接口是jdk8的新特性，有了函数式接口（不是必须要声明为@FunctionalInterface），我们可以引用方法，然后独自调用方法。很关键的一点，你的引用方法的参数个数、类型，返回值类型要和函数式接口中的方法声明一一对应才行。（相当于一个函数模板）

这里提一嘴关于lamda表达式的注意点：表达式内不能修改外部局部变量的值（引用类型和数组对象除外）

```
MyFunction function = Integer::compare;
System.out.println(function.apply(1,2));
```

#### 流Stream

Java 8 API添加了一个新的抽象称为流Stream,并且大部分接口都是接受方法引用作为参数，可以让你以一种声明的方式处理数据。Stream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。

这种风格将要处理的**元素集合看作一种流**， 流在**管道中传输**， 并且可以**在管道的节点上进行处理**， 比如筛选， 排序，聚合等。

元素流在管道中经过中间操作（intermediate operation）的处理(仍然返回流)，最后由最终操作(terminal operation)得到前面处理的结果。**注意：stream中的每一步并不是直接依次执行的，只有在发起终端操作时，才会对源数据进行计算且只使用需要的元素**

**流只能被使用一次，不可以被再次使用。**

      //Stream操作
      list = list     //链式调用
              .stream()    //获取流
              .filter(e -> !e.equals("B"))   //只允许所有不是B的元素通过流水线
              .collect(Collectors.toList());   //将流水线中的元素重新收集起来，变回List
      System.out.println(list);
    
              //有没有发现就像sql一样
          list = list
                  .stream()
                        .distinct()   //去重（使用equals判断）
                  .sorted((a, b) -> b - a)    //进行倒序排列
                  .map(e -> e+1)    //每个元素都要执行+1操作
                  .limit(2)    //只放行前两个元素
                  .collect(Collectors.toList());

当遇到大量的复杂操作时，我们就可以使用Stream来快速编写代码，这样不仅代码量大幅度减少，而且逻辑也更加清晰明了

#### 并行Stream

Stream 本质上来说就是用来做数据处理的，为了加快处理速度，Stream API 提供了并行处理 Stream 的方式。通过 `users.parallelStream()`或者`users.stream().parallel()` 的方式来创建并行 Stream 对象，支持的 API 和普通 Stream 几乎是一致的。

注意点：

1. 要在多核CPU上使用
2. 适合CPU密集型计算
3. 有些操作，比如 limit、 findFirst、forEachOrdered 等依赖于元素顺序的操作，都不适合用并行 Stream。

#### Optional类

Optional类是Java8为了解决null值判断问题，使用Optional类可以避免显式的null值判断（null的防御性检查），避免null导致的NPE（NullPointerException）。总而言之，就是对控制的一个判断，为了避免空指针异常。

```java
public static void main(String[] args) {
    String str = null;
    Optional<String> optional = Optional.ofNullable(str);   //转换为Optional
    optional.ifPresent(System.out::println);  //当存在时再执行方法
}

public static void main(String[] args) {
    String str = null;
    Optional optional = Optional.ofNullable(str);   //转换为Optional（可空）
    System.out.println(optional.orElse("lbwnb"));
         // System.out.println(optional.get());   这样会直接报错
}
```

#### 如何将基本数据类型数组变为包装类List

```
int[] myArray2 = {1,2,3};
List myList = Arrays.stream(myArray2).boxed().collect(Collectors.toList());
System.out.println(myList);
```

#### 简单介绍一下HashMap

HashMap是基于哈希表的对Map接口的实现，它实现了所有Map的操作，且不同于HashTable，它允许空值且不是线程安全的。

在jdk8中，hashmap的底层使用数组与链表和红黑树来存储键值对，并在必要的时候扩充数组容量。

hashMap有两个重要的初始时可选参数：初始容量与负载因子，初始容量可以指定哈希表的初始大小，默认是16，但是会调整为2的整数次幂，负载因子决定哈希表何时扩容，默认是0.75，这个值在空间与时间成本之间提供了良好的折中。这两个参数配置合理对hashmap的性能有很大的帮助（减少扩容与hash冲突）

#### HashMap

##### 1.7 与 1.8的区别

1.7 使用的数据结构是数组+链表 1.8 是数组+链表+红黑树（树化条件，插入后数组长度大于64且链表长度大于8 如果只满足长度大于等于8只会扩容），以优化查询效率

需要注意的是：**树化并不是一个正常情况，几率很小**

##### 键值对的存放结构

存储在Node类中，这是链表用的类，有指向下一个Node的指针

如果是红黑树，则存储在TreeNode中，这是一个红黑树结点。

##### hashMap的初始化

```java
public HashMap(int initialCapacity, float loadFactor) {
    //省略了一些代码 主要是一些特殊情况

    this.loadFactor = loadFactor;
    // 将初始容量赋值给threshold 这个是扩容阈值
    this.threshold = tableSizeFor(initialCapacity);
}
public HashMap(int initialCapacity) {
    this(initialCapacity, DEFAULT_LOAD_FACTOR);
}

//默认构造函数 可见tab这时候并没有初始化 
public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}

    // 这个方法将容量扩大到最接近的2的整数次幂
// 对任意十进制数转换为2的整数幂，结果是这个数本身的最高有效位的前一位变成1，最高有效位以及其后的位都变为0。
//核心思想是，先将最高有效位以及其后的位都变为1，最后再+1，就进位到前一位变成1，其后所有的满2变0。所以关键是如何将最高有效位后面都变为1。

    static final int tableSizeFor(int cap) {
        //为何减一？因为如果cap原本就是2次幂 不减一无法返回它本身.
        int n = cap - 1;
        // 假设n的第20位为1，那么我们将它右移一位在于n或运算，是不是第20位与第19位都是1了呢
        n |= n >>> 1;
        // 在之前的基础上，再右移两位，也就是19、20位的1移到了17、18位，再或运算，是不是4个1？
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        //以此类推，我们通过最后一步右移16位，可以把最高位1后面的所有位数都变为1（32位整数）
        n |= n >>> 16;     
        // 最后n+1 就一定是2次幂
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
```

##### 红黑树何时退化

- 在扩容时如果拆分树，节点小于等于6，则退化为链表
- remove树节点时，若root、root.left、root.right、root.left.left中有一个节点是null，也会退化

##### 索引计算

通过hash()函数计算（获取更佳的hash值）   `index = hashCode()&(n-1)` 前提：除数必须是2的n次方 目的：追求性能，但分布性会降低

正常求哈希值，都是hashCode()%n 但是如果n是2次幂，则这两个值是相等的,从而提高性能。

##### put流程

```java
    public V put(K key, V value) { // 返回的值是oldvalue
        return putVal(hash(key), key, value, false, true);
    }
```

```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;  //1 判断tab是否是空，如果是则扩容
    if ((p = tab[i = (n - 1) & hash]) == null) //2 判断当前桶是否空，如果是则直接放入
        tab[i] = newNode(hash, key, value, null);
    else { // 3 找到一个key相等的节点 或者不存在则创建一个新节点插入
        Node<K,V> e; K k;
        if (p.hash == hash &&            
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        else if (p instanceof TreeNode) // 3.1 如果是红黑树，使用树化插入
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else { // 3.2 链表尾插法插入
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {  // 3.3不存在则插入节点
                    p.next = newNode(hash, key, value, null);
                    if (binCount >= TREEIFY_THRESHOLD - 1) //如果大于8则树化或扩容
                        treeifyBin(tab, hash); // 注意 如果此时数组长度没有64 执行的是扩容
                    break;
                }
                if (e.hash == hash && // 3.4 找到key相等节点
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        if (e != null) { //4 判断是否需要替换value
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    if (++size > threshold) // 5 执行了插入元素之后，判断是否要扩容
        resize();
    afterNodeInsertion(evict);
    return null;
}
```

##### resize流程

```java
/**
 * 初始化或者扩大一倍数组大小.  如果数组是null,则分配由threshold指定的大小容量。
 * 否则就是扩容，涉及到元素的移动，由于我们的数组大小是二次幂，所以桶中的元素要么不动，要么移动到偏移量为n+x的桶里面
 * @return the table
 */
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) { // 这里是真正的扩容
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab; // 超过最大容量不会扩容,直接返回
        }
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY) // 如果原来的cap太小（猜测是因为cap太小会有小数，影响精确度）、newCap太大，newThr不会赋值，值由下面给出
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // 指定了初始大小的map到这里
        newCap = oldThr;
    else {               //默认构造函数的map会执行这里
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) { // 这里给出自定义初始容量 或者上文说到的特殊情况的newThr
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {  // 初始化tab不会走这里 这是扩容移动元素
        for (int j = 0; j < oldCap; ++j) { // 逐个遍历桶
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e; // 先把头结点放在newTab中
                else if (e instanceof TreeNode) // 如果是树结点，就要执行树的分裂（这里会有红黑树的退化）。
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // 链表的情况下维护了两条链表，最后插入指定桶
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) { // 我们知道只有两种情况 如果是0，说明要在老桶里面(因为其实newCap就是比oldCap的1左移了一位，如果hash中oldCap的1的那一位不是1，说明一定是在老的桶里面,否则和newCap-1与操作后肯定在新桶里）
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

##### get流程

```java
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}


 // hash值，key
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    // 这个判断：表示初步判断这个key是否存在 tab存在且长度大于0 定位的桶里面有元素
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        if (first.hash == hash &&
            // 总是先检查第一个元素 为何？因为后续结点遍历写起来更方便，毕竟第一个结点不是由next指向的
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            // 如果是红黑树结点，那么就执行红黑树的搜索
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            do { // 否则遍历链表
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
```

##### 补充

下面三个方法是空实现，主要用于LinkedHashMap 维护一个双向链表

```
void afterNodeAccess(Node<K,V> p) { }
void afterNodeInsertion(boolean evict) { }
void afterNodeRemoval(Node<K,V> p) { }
```

#### LinkedHashMap

它继承自HashMap，与hashMap不同的是维护了插入的结点的双向链表，以确定结点的插入顺序.(可以指定是插入顺序还是访问顺序)

通过重写父类的几个空方法，实现自己链表的维护。

#### ArrayList?

基于Object数组，连续内存，支持随机访问，尾部插入删除性能较佳，其他移动插入删除操作性能会下降

因为存储空间连续，可以利用局部性原理，加快读取速度。

ArrayList中对底层数组的操作用到了很多`System.arraycopy()` 方法 

##### 扩容机制

调用无参构造函数，初始容量是0，插入元素后，扩容到10

如果空间用完，扩容大小为1.5倍（调用add方法）

如果调用addALL方法，会选择一个原长度1.5倍与最小要求容量两者间的最大值作为新容量

` 比如  原来有10个元素，添加三个 则扩容后大小为15`

##### fail-fast / fail-safe

迭代器有关

fail-fast: 指在遍历的同时，一旦数组元素作了修改（不是迭代器对象进行的修改），立即抛出异常

fail-safe: 发现遍历的同时有修改，应该能有策略，使遍历能够执行下去（牺牲一致性,生成一个遍历开始时候的快照）

#### LinkedList

基于双向链表实现，访问元素需要遍历链表，头插尾插性能高，占用内存更高。

### JVM篇

#### 四种引用概述与区别？

强引用：最常见的引用，最普遍的引用赋值即为强引用，强引用的对象在任何情况下都不会被回收。

软引用：用来描述一些有用，但非必须的对象，只被软引用关联的对象会在将要发生内存溢出异常前，jvm会把这些对象列进回收范围进行第二次回收。SoftReference

弱引用：只被弱引用关联的对象只能活到下一次垃圾收集发生为止。不论当前内存是否足够，都会回收对象。WeakReference 可以与引用队列配合使用，对关联对象进行进一步垃圾回收（被回收的弱引用对象会加入引用队列中）。

虚引用：最弱的一种引用，无法通过虚引用来获得对象实例。为一个对象设置虚引用关联的目的是能在这个对象被收集器回收时收到一个通知。PhantomReference 必须与引用队列配合使用

Cleaner对象 简化对象被回收时的垃圾施放 使用cleaner.register(回收对象，lamda表达式) 进行回收操作

#### JNI

JNI是指JAVA 本地接口，是java程序调用其他语言C/C++函数的一种方式，程序中声明的native方法，就是这种接口的体现。

#### JVM内存区域？

不像C语言那样，程序员手动申请释放内存，而在java里对于内存的分配与回收，是JVM帮我们自动完成的，但是这样一旦出现了内存相关的问题，如果不了解JVM的内存管理机制，可能就很难发现问题所在。所以我们有必要了解JVM内存管理机制。

JVM在执行JAVA程序时，会把它管理的内存划分若干不同的数据区域，分区治理，主要包括：堆、方法区、程序计数器、虚拟机栈、本地方法栈

##### 程序计数器：

模拟的是硬件机器的PC，功能也是类似的。

是一种指令寄存器，字节码执行引擎控制，表示当前执行的字节码指令地址，，占用空间也很小。为了线程切换之后能够恢复线程，每个线程都应该有一个程序计数器，是线程私有的。如果正在执行本地方法，这个计数器值为空。

##### 虚拟机栈：

描述的是JAVA方法执行的线程内存模型，作用是让线程正确的进行方法调用。每个方法被执行时，JVM都会同步创建一个栈帧，用于存放局部变量表、操作数栈、动态连接、方法出口等信息。一个方法的执行开始与结束，就代表栈帧的入栈与出栈。虚拟机栈是线程私有的，并且生命周期与线程相同。

若深度超过最大深度，则会抛出stackoverflowError

**栈帧**虚拟机栈内的基本单元，用于支持虚拟机进行方法调用和方法执行。栈帧包含局部变量表、操作数栈、返回地址、动态连接

**局部变量表**用于存放方法内部定义的局部变量，包含了编译期可知的各种基本数据类型、对象引用类型。存放的单元为slot。double与long会占用两个slot。注意slot的数量是完全确定的，不会在方法运行期间改变。

**操作数栈**是由字节码执行引擎操作的（字节码解释执行引擎被称为基于栈的执行引擎，这个栈指的就是操作数栈），在执行各种字节码指令时，会涉及到对操作数栈的数据存入与读取，由操作数栈来保存中间结果、方法参数传递。

此外，为了让方法调用时，可以直接共用一部分数据，减少额外的参数传递，栈帧之间会出现一部分重叠（操作数栈和另一个栈帧的局部变量表）

**返回地址**指方法执行结束退出后，应该返回的位置，使程序能继续运行，同时栈帧也会保存一些信息帮助恢复现场

**动态连接** 每个栈帧还保存了一个**可以指向当前方法所在类**的运行时常量池，目的是：当前方法中如果需要调用其他方法的时候，能够从运行时常量池中找到对应的符号引用，然后将符号引用转换为直接引用，然后就能直接调用对应方法

对于静态类型，这些符号引用会在类加载阶段或者第一次调用时替换为直接引用（静态解析）；但是JAVA是支持多态的语言，所以对于多态类型，需要在实际运行时才能确实具体是哪一种类型，所以对它符号引用的解析，就要在每一次运行期间转换。

##### 本地方法栈：

与虚拟机栈类似，但是是为本地方法服务的。

若深度超过最大深度，则会抛出StackOverflowError

##### 堆

堆是JVM管理的内存区域中最大的一块空间，作用是存放与管理对象实例和数组。几乎所有对象都是在堆里分配内存的。堆也是JVM垃圾回收的主要区域。对于基于分代收集理论的垃圾收集器，一般会将堆划分为不同的区域提高内存回收的效率。

从内存分配的角度来讲，JAVA堆为了方便对象的内存分配，在堆中会划分出多个线程私有的分配缓冲区（TLAB），提升对象分配的效率。

堆内存不足以分配实例，且无法扩展时，会抛出OOM

##### 方法区

方法区用于存储已经被虚拟机加载的类的类型信息，常量、静态变量、动态编译缓存等数据。

可以大致分为两个部分：类信息表以及运行时常量池

类信息表中存放的是当前应用程序加载的所有类信息，包括类的版本、字段、方法、接口等信息，同时会将编译时生成的类常量池数据全部存放到运行时常量池中。在程序运行时，也有可能会有新的常量进入到常量池。

##### 方法区的实现：

JDK8以前，称为永久代，永久代有大小上限，容易发生内存溢出的问题，JDK8以后，成为元空间，改用本地内存来实现方法区，把字符串常量池（这里注意一下intern()方法，1.7之后，如果字符串常量池没有对应字符串，创建的不是字符串而是指向对象的引用）以及静态变量移出方法区。

运行时常量池是方法区的一部分，Class文件中的常量池表（编译期生成的各种字面量与符号引用）在类加载后会存放到运行时常量池。

当方法区无法满足分配时，会抛出OOM

##### 直接内存

除了堆可以存放对象实例数据，也可以用户申请直接内存（堆外内存），直接内存并不是由JVM直接管理的，这部分内存需要用户自行去申请和释放。不过虽然是直接内存，不会受到堆内存容量限制，但是依然会受到本机最大内存的限制，所以还是有可能抛出`OutOfMemoryError`异常。

这部分内存的申请与释放需要用到Unsafe类对象（底层调用c++的malloc方法）。

#### 对象内存的分配？

内存分配的两种方式：指针碰撞（将指针向空闲区域移动）、空闲链表（维护所有空闲的空间）

但是对象内存的分配并不是线程安全的，一个解决办法是使用同步的方式来分配内存（CAS），一个是在堆中提前分配一部分内存给线程使用（TLAB）

#### 对象的创建过程？

1. 当遇到一个new指令时，首先检查这个指令的参数能否在常量池中定位到一个类的符号引用，并且检查这个符号引用对应的类是否已经被加载、解析与初始化
2. 为对象分配内存空间
3. 将分配的内存空间初始化0值，并设置对象头
4. 执行实例构造器的<init>方法，按照程序员的意愿进行初始化。

#### 判断对象是否需要回收的方法？

##### 引用计数法

在对象中添加一个引用计数器，如果为0，则表示对象需要回收。坏处：需要配合很多额外工作才能保证正确工作，比如对象之间的相互引用。

##### 可达性分析

从GCROOTS的对象开始，根据引用关系向下搜索，如果一个对象不在引用链上，则需要回收。

类似于一种树结构。

可以作为ROOTS的对象：

1. 虚拟机栈中局部变量表中的对象
2. 静态变量
3. 常量引用的对象
4. Class对象 常驻异常对象
5. 本地方法栈中引用的对象
6. 被同步锁持有的对象

###### 对象回收的最终判定

被可达性分析判定为需要回收的对象并不一定会被最终回收，对于不在引用链上的对象，其会被第一次标记，并进入F-Queue中，最后执行finalize方法，之后根据情况被回收，如果其能在finalize中重新被引用，则不会被回收。

（但是一般不推荐重写finalize方法）

（同一个对象的`finalize()`方法只会有一次调用机会，也就是说，如果我们连续两次这样操作，那么第二次，对象必定被回收）

##### 根节点枚举

使用oopMap的数据结构，虚拟机通过这个数据结构能够直接得到哪些地方存在这对象引用，并不需要一个不漏真正从方法区等GCROOTS开始枚举。

##### 安全点/安全区域

不可能为每一条指令都去生成对于的oopMap，只会在特定的位置进行更新，这些位置被称为安全点，而安全区域是为了针对线程在被阻塞的时候没法运行到安全点而无法进行GC，安全区域是指一段代码片段中，引用关系不会发生变化的区域。线程必须执行到安全点或者安全区域后才能进行垃圾收集。

#### 垃圾收集算法？

垃圾收集器会不定期地检查堆中的对象，查看它们是否满足被回收的条件。而该如何对这些对象进行回收，就是垃圾收集算法决定的。

##### 分代收集理论

1. 绝大多数对象朝生夕灭
2. 存活时间越长的对象越难以消亡
3. 跨代引用仅占极少数（解决跨代引用的办法：记忆集）

根据这三条法则，将堆的内存区域分为新生代与老年代，对两个区域使用不同的垃圾回收算法

鉴于新生代对象大部分都会灭亡，所以大部分垃圾收集器都对这部分区域使用标记复制算法。一般来说在新生代中会划分出Eden区和两个survivor区域，默认比例为8：1 每次分配内存只使用其中的新生代和一块s区。垃圾回收时，将存活对象移动到另一个s区，然后年龄+1（如果年龄大于15或者说，动态年龄判断成立）。如果说，s区放不下存活对象（极少数情况）,那么会有一个逃生门机制，通过分配担保机制，将一部分对象提前分配在老年区。

而垃圾收集等级也分为：

- MinorGC 新生代eden区容量满时触发，回收新生代空间
- MajorGC 主要进行老年代垃圾回收
- FullGC 对整个堆内存与方法区进行垃圾回收，最耗资源与时间
  - 每次晋升到老年代的对象大小超过了一定的限制
  - MinorGC存活对象超过老年代剩余空间
  - 调用System.gc()

##### 垃圾回收算法

- 标记-复制

将垃圾回收的区域分为两部分，每次对一部分进行回收，将存活的对象复制到另一个区域,会浪费掉一部分的空间

- 标记-整理

因为标记复制算法会损失百分之50空间，而标记清除算法会产生很多碎片

所以标记整理算法的思想是将不需要回收的对象整齐排列在一段内存空间，而需要回收的往后排，然后一次清除后续内存

效率必另外两者都低，而且涉及到对象的移动，所以需要STW

- 标记-清除

将可以清除的垃圾对象直接原地清除，释放内存。可能会有很多的碎片

##### 并发的可达性分析 三色标记

与用户线程并发的可达性分析可能会引发严重的问题，我们使用三色标记来帮助分析问题。

​    白色：未被访问过

​    黑色：已被访问过，所有引用已被扫描

​    灰色：对象已被访问过，但其直接引用还没有完全扫描

黑色对象被误标为白色（引用关系的变化）会引发严重的错误！ 

解决方案：增量更新、原始快照

#### 经典的垃圾收集器？

##### Serial垃圾收集器

单线程垃圾收集器

简单高效，客户端模式下的默认新生代垃圾收集器（因为客户端应用内存不会特别大） 标记复制算法

##### SerialOld垃圾收集器

Serial垃圾收集器老年版本 标记整理算法

##### ParNew垃圾收集器

Serial垃圾收集器的多线程版本 新生代收集器 能与CMS配合工作

##### Parallel Scavenge （java8 服务端默认）

注重程序的吞吐量的多线程垃圾收集的新生代垃圾收集器  可以设置要达到的吞吐量大小与最大停顿时间。

##### Parallel Old

Parallel Scavenge老年版本

##### CMS

CMS收集器是一种**以最短回收停顿时间为目标**的收集器，也是第一个并发的垃圾收集器。老年代垃圾收集器。从名字就可以看出，CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几个收集器来说更复杂一点，整个过程分为4个步骤：

- 初始标记（initial mark）
- 并发标记（concurrent mark）
- 重新标记（remark）
- 并发清除（concurrent sweep）

其中，初始标记和重新标记仍然需要“Stop The World”。初始标记仅仅标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段是进行GC Roots Tracing的过程，而重新标记则是为了修正并发标记期间用户程序继续运作而导致的标记变动，这个阶段的停顿时间一般会比初始阶段稍长，但是远比并发标记阶段耗时短。

使用**增量更新算法**，保证黑色节点不被误标记为白色节点。

由于整个过程中耗时最长的并发标记和并发清除过程都可以和用户线程一起工作，所以总体来说CMS收集器的内存回收过程是和用户线程一起并发执行的。

但是，CMS同样有以下明显的缺点：

- CMS收集器对CPU资源非常敏感，默认启动了（CPU数量+3）/4个线程执行回收，也就是当CPU在4个以上并发回收时收集线程占用不少于25%的CPU资源，并且随着CPU数量增加而下降。CPU数量少的时候对用户的影响就很大了。
- CMS无法处理浮动垃圾（Floating Garbage），可能出现`Concurrent Mode Failure`失败而导致另一个Full GC产生。即CMS在并发清除过程中产生的新的垃圾，只能在下一次GC时再处理。
- **最后一个缺点**，由于CMS基于“标记-清除”算法实现，意味着收集结束可能会有大量的空间碎片产生。空间碎片过多会对大内存分配产生麻烦，导致分配内存的时候不得不提前触发Full GC。所以CMS在内存碎片化达到一定程度会通过标记整理算法对内存进行整理。

##### G1垃圾收集器

面向全堆的垃圾收集器，主要面向服务端应用。面向局部收集和基于Region的内存布局。

它将整个堆分成2048个大小相同的独立区域，称为Region，所有Region大小相同，且在JVM整个生命周期都不会改变

分代回收的概念在G1中仍然存在，每一个`Region`都可以根据需要，自由决定扮演哪个角色（Eden、Survivor和老年代），收集器会根据对应的角色采用不同的回收策略。此外，还存在一些Humongous区域，它专门用于存放大对象（一般认为大小超过了Region容量一半的对象为大对象）。这样，新生代与老年代在内存空间上就不是一个连续的区域了

G1是jdk9版本之后JVM默认的垃圾收集器，它具有以下特点：

- 并行和并发：G1可以充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短Stop The World停顿的时间。
- 分代收集：分代概念仍然在G1中保留，但是G1可以不需要与其他收集器配合独自管理整个GC堆。
- 空间整合：与CMS的“标记-清理”算法不同，G1从整体上看是基于“标记-整理”算法实现，但是从局部（两个Region）来看是基于“复制”算法实现的。无论如何，G1运作期间不会产生内存碎片，收集完成后可以提供规整可用的内存。
- 可预测的停顿：这是G1相对于CMS的另一大优势，G1除了追求低停顿之外，还能建立可预测的停顿时间模型，让使用者明确指定在一个长度为M毫秒的时间片断内，消耗在垃圾收集上的时间不超过N毫秒。

G1收集器之所以能建立可预测的时间模型，因为它有计划地避免在整个Java堆中进行全区域的垃圾收集。G1追踪各个Region里面垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的时间优先回收价值最大的Region。

G1中每个Region都有一个与之对应的Remembered Set，存放跨区域引用信息。

**G1收集器的运作大致可以分为以下几个步骤：**

- 初始标记（Initial Marking）标记一下GC Roots能直接关联到的对象，并且修改TAMS的值，让下一阶段用户程序并发运行的时候，能在正确可用的Region中创建对象
- 并发标记（Concurrent Marking）从GC Roots开始进行可达性分析，这个阶段耗时较长但是可以和用户程序并发执行
- 最终标记（Final Marking）修正并发标记阶段产生的标记变动，合并到记忆集中
- 筛选回收（Live Data Counting and Evacuation）对各个Region的回收价值和成本排序，根据用户指定的GC停顿时间来制定回收计划。（需要停顿）

##### 低延迟垃圾收集器

停顿时间基本上固定，与堆中对象没有正比关系的垃圾收集器 ZGC等

#### 内存分配和回收策略

Java的内存管理可以归结为内存的自动分配和自动回收，上面讲了内存回收的策略，下面再说一下内存分配。

##### 对象优先在Eden分配

大多数情况下，对象在新生代Eden区中分配，当Eden区没足够空间的时候，虚拟机将发起一次Minor GC。

##### 大对象直接进入老年代

所谓大的对象是指需要大量连续空间的Java对象，最典型的是很长的字符串和数组。

虚拟机提供了`-XX:PretenureSizeThreshold`参数，令大于这个设置值的对象直接在老年代分配。目的是避免Eden区及两个Survivor区之间大量的内存复制。

##### 长期存活的对象进入老年代

为了分配哪些对象放在新生代，哪些放在老年代，虚拟机给每个对象定义了一个对象年龄（Age）计数器，如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor中每经过一次Minor GC，年龄就增加一岁，当年龄增加到一定成都（默认是15岁），就会被晋升到老年代，这个阈值可以通过参数`-XX:MaxTenuringThreshold`设置。

##### 动态对象年龄判定

为了适应不同程序的内存状况，不是只有对象年龄大于MaxTenuringThreshold才能晋升老年代。如果Survivor空间中相同年龄所有对象大小总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。

##### 空间分配担保

在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有的对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看`HandlePromotionFailure`设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于晋升到老年代对象的平均大小。如果大于就尝试进行一次Minor GC，尽管这次GC是有风险的。如果小于，或者不允许冒险，就改为进行一次Full GC。

#### 类加载机制？

当我们需要用到某一个类的时候，要先加载类的字节码文件到JVM中，然后才能使用

JVM把描述类的数据从Class文件中读取到内存，并对数据进行校验、解析与初始化，最后形成可以被虚拟机使用的Java类型的过程成为类加载机制，这一过程时在程序运行期间完成的。

##### 类加载过程

- 加载

​    读取一个class文件，将其转化为某种静态数据结构，存储在方法区，并在堆中生成Class对象

- 验证

​    确保class的字节流数据符合规范（魔数是否合法、主次版本号是否可以由当前JVM运行、Class文件的各个部分是否完整），不会危害虚拟机自身的安全。

- 准备

​    为类中定义的静态变量分配内存，设置初始值

- 解析

​    将类常量池中的符号引用替换为直接引用（直接引用就可以理解为内存中真正存在的地址，可以通过直接引用找到它） 解析时机未作规定，这个步骤可以发生在初始化之后

- 初始化

​    执行类构造器的<clinit>方法（收集static代码块与静态变量赋值自动生成这个方法）

​    **几个会不触发初始化的操作**

​            子类使用父类的静态变量 子类不会初始化

​            数组定义引用类 不会出发类的初始化

​            使用定义的常量 不会触发类的初始化

- 使用

- 卸载

#### 类加载顺序？

```
class Parent{
    private int a =intc();
    static {
        System.out.println("A");
    }
    public Parent(){
        System.out.println("D");
    }
    public int intc(){
        System.out.println("C");
        return 1;
    }
}
class Child extends Parent{
    public Child(){
        System.out.println("F");
    }

    public int intd() {
        System.out.println("E");
        return 1;
    }

    private int b = intd();

    static {
        System.out.println("B");
    }
}
// 执行了new Child() 后 输出顺序？
父类静态代码块 子类静态代码块 父类成员变量赋值 父类构造函数 子类成员变量赋值 子类构造函数 
```

#### 类加载器

任何一个Java类，都必须要经过加载它的类加载器与它自身确定在JVM中的唯一性，同一个class经由不同类加载器加载，也是不同的类。

每个类可以被不同的类加载器加载，而生成不同的Class对象，所以一个类可能对应了多个Class对象

##### 几种类加载器

启动类加载器

由c++实现，无法作为对象被程序引用，只加载位于/lib目录下的核心类

扩展类加载器

加载位于/lib/ext下的类或者有系统变量制定的类 主要加载一些对java api的拓展的类

应用类加载器

加载位于classpath下的类 即自己的代码与第三方类库

自定义类加载器

继承classLoader ，实现loadClass方法 

##### 双亲委派

类加载器将当前加载类的任务委派给父类加载器，除非父加载器无法加载才会自己尝试加载。

双亲委托模式的破坏：继承classLoader,重写loadclass  重写findclass不破坏双亲委派

好处：类加载器之间具有了层级关系，保证系统的核心类库不会被破坏，减少程序的混乱

破坏双亲委派的应用：JNDI、JSP、热部署

#### JVM调优

##### 相关参数：

```
-Xms<heap size>[unit] 
-Xmx<heap size>[unit]
// 新生代大小
-XX:NewSize=<young size>[unit] 
-XX:MaxNewSize=<young size>[unit]
-Xmn256m 
// 新生代与老年代比例
-XX:NewRatio=1
// 元空间大小
-XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小）
-XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。
// 选择垃圾收集器
-XX:+UseSerialGC
-XX:+UseParallelGC
-XX:+UseParNewGC
-XX:+UseG1GC
```

##### 性能分析工具

/bin目录下有许多性能分析的小工具

- jps 列出正在运行的JVM进程
- jstat 统计信息监视工具 显示内存、类加载、垃圾回收等数据
- jmap 生成堆转储快照
- jhat
- jstack 堆栈信息，生成线程快照
- visualVM 可视化性能分析工具

### 多线程篇

#### 如何减少线程的上下文切换？

1. 使用无锁并发编程方法（CAS、缩小锁的粒度等）
2. 尽量使用尽可能少的线程，避免创建不必要的线程

#### 避免死锁的常见方法

1. 避免在一个线程同时获得多个锁
2. 尽量保证每个锁只占用一个资源
3. 尝试使用定时锁，到时候自动释放、或者超时放弃获取锁
4. 对于数据库锁，加锁与解锁要在一个数据库连接里面，否则会出现解锁失败的情况

#### 缓存一致性？

为了解决处理器速度与内存速度的差异，引入了高速缓存。每个处理器都有自己的高速缓存，且共享同一个主存。当多个处理器的运算任务涉及同一块主内存区域时，可能会导致各自缓存的数据不一致。所以各个处理器访问缓存时都需要遵循一些协议。

缓存一致性协议定义了缓存行的四种状态，M E S I，由各CPU的缓存控制器嗅探总线控制状态的转换，从而保证独占缓存之间的一致性。

#### 指令重排序？

重排序是为了提高cpu的利用率，而对执行的指令顺序进行重排序。

重排序分为三种类型

- 编译器重排序，但是不嫩改变程序执行结果
- 指令级并行重排序（多个CPU并行执行指令以及指令的重排序）
- 内存系统重排序 由于处理器使用了读/写缓存，导致加载和存储的操作可能是乱序执行

前者是编译器级别的重排序

后两种是处理器重排序

插入特定类型的内存屏障可以禁止特定指令的重排序

#### JMM内存模型？

JMM是JVM的内存模型，由于java是跨平台的，而不同OS的内存模型不尽相同，所以JVM有必要有自己的内存模型，屏蔽系统差异。同时，JMM还是JAVA并发编程的规范与原则，有了JMM之后，可以简化多线程编程（Happens-before原则等）

JMM是一种共享内存模型，它规定所有的变量（实例字段、静态字段、构成数组对象的元素，不包括局部变量）都存储在主内存，每条线程有自己的工作内存，工作内存中保存了被该线程使用的变量的副本。线程对变量的所有操作必须在工作内存中进行。

##### 内存间的交互操作

JVM定义了8种原子操作完成变量在主存与工作内存间的读写

```
lock
unlock
read load
use assign 工作内存-字节码执行引擎
store write 
最新简化为： read write lock unlock
对一个变量执行lock，将会清空工作内存中此变量的值

对一个变量执行unlock前，必须先把此变量同步到主内存
```

#### volatile关键字？

被声明为volatile的变量具有两个特性

1. 可见性：当一个线程修改了这个变量的值，新值对于其他线程是可见的。也就是说，对一个volatile的读，总是能够读取到对这个volatile变量最后的写。同时每个v读读取到的，都是最新值
2. 禁止特定的指令重排序优化（内存屏障）

注意volatile只保证了可见性，而原子性并不保证

#### voliate读-写的内存语义（即读写特性）

之所以volatile具有上述的两个特性，是因为其具有如下内存语义

当读取一个voliate变量时，会把该线程对应的工作内存中的共享变量设为无效。线程接下来将从主存读取。

当写一个v变量时，会把该线程对应的本地内存中的共享变量值刷新到主存中

voliate的内存语义与**锁的施放与获取的内存语义是相同的**(也就是说线程获取与释放锁也会有上述的语义)，我觉得这也正是JUC中的Lock可以不用sychornized而是使用一个voliate变量的原因之一.

#### 内存屏障

JMM把内存屏障分成4类

load1 **LoadLoad** load2 确保load1数据的装载先于load2以及后续所有装载指令的装载

store1 **StoreStore** sotre2 确保store1数据对其他处理器可见（刷新回主存）先于store2及后续所有存储指令

load1 **LoadStore** store2 确保load1数据的装载先于store2存储指令刷新到主存

store1 **StoreLoad** load2 确保store1数据对其他处理器可见先于Load2指令数据装载 **是一个全能屏障 具有其他三个屏障的效果 该屏障前的内存访问指令 必须发生与该屏障后的内存访问指令** ，同时执行该指令开销也比较大。

#### voliate内存语义的实现原理

voliate内存语义的实现还是基于不同的内存屏障

- 当第二个操作是v写时，不管第一个操作是什么都不能重排序
- 第一个操作是v读时，不管第二个操作是什么都不能重排序
- v写-v读不能重排序

对于V写，在写之前插入SotreStore屏障，在写之后插入StoreLoad屏障

对于V读，在读后面插入LoadLoad屏障和LoadStore屏障

#### final的内存语义

构造函数中对final变量的写操作先于随后把被构造的对象赋值给一个引用变量。（如果final是对象，那么变为对final对象内成员变量的写）

初次读一个包含final的对象的引用，先于读这个对象内的final域

#### 以下哪些操作不是原子操作？

int a = 1 是

int a = b 不是 涉及到读取b 赋值给a

a++ 不是

String a = anotherObj 是 引用赋值是原子的

#### Happens-before原则

1. 如果一个操作happens before 另一个操作，则JMM保证第一个操作对于第二个操作可见
2. 两个操作之间存在hb关系，并不意味着第一个操作要先于第二个操作执行，只需要执行结果与顺序执行的结果一致，则允许这种重排序。

它是用于判断数据是否存在竞争，线程是否安全的有用手段

也可以方便程序员理解JMM内存模型的可见性

A H-B B表示A的操作对于B是可见的   **时间上的先发生并不代表操作先行发生**

有8大原则 是JMM的天然先行发生关系 无需任何同步即存在，可以在编码中直接使用 如果无法从这些原则中推到出来，则顺序性没有保障，JVM可以对他们随意进行重排序。

#### as-if-serial原则

指不管怎么重排序，单线程程序执行的结果都不能被改变

#### 线程模型 线程的实现方式？

##### 内核线程实现 1：1

内核线程是指由内核直接支持的线程，其通过调度器将任务分配给各个cpu上，即完全由操作系统进行调用。程序使用的是内核线程的高级接口，轻量级进程，其与内核线程一一对应。1:1模型中，每个LWP都是一个独立调度单位，即使阻塞也不会影响整个进程。

##### 用户线程实现 N：1

用户线程指完全有用户线程库实现的线程，内核感知不到用户线程的存在以及如何实现，所以线程的建立销毁调度不需要切换到内核态。但是实现很复杂，需要处理很多问题。

##### 混合实现 N:M

将上述两种方式混合使用。用户线程仍然存在于用户空间，并且可以支持大规模并发要求；同时LWP的存在使其拥有了内核的调度能力，减少完全阻塞的风险。

#### 线程的状态？

新建

运行

等待 **线程等待其他线程唤醒** 

有限等待

阻塞 **线程等待锁**

终止

#### JAVA的线程中断

java的线程中断可以通过调用interrupt()方法实现，但是使用时有以下注意点：

1. 如果当前线程正在通过sleep等待，则会抛出中断异常
2. 如果当前线程正在通过LockUnsupport.park()进入等待，则会修改标志位，从等待中恢复
3. 如果当前线程正常运行，则只会修改标志位
4. `isInterrupted()`方法返回中断标志位，且重置标志位的值

#### CAS?

是一种乐观锁，并不是真的加锁

线程先读取资源的oldValue 进行操作后，看oldvalue和当前资源的值进行比较，一样就写入，不一样就不写入，进行回旋（默认10次）

为什么cas一定要原子操作（比较与替换一次性完成）？ 因为两个线程读取了数据，在判断可以写入之后，A先写入了，B也写入了）  cas的原子性由cpu指令实现

#### cas的问题

1. ABA问题
   
   1. 如何解决？添加一个版本号，每次设置成功就+1

2. 过长的自旋会消耗cpu资源
   
   1. 限制自旋次数

3. 只能保证一个共享变量的原子操作
   
   1. AtomicReference类

#### Lock与synchorzined区别？

1. sychorzined是关键字，由C++语言实现
2. Lock是接口，由java实现
3. 使用sychorzined时，锁自动施放，而lock接口需要手动施放锁
4. lock有更加丰富的功能，比如可中断获取锁、公平锁、多个等待队列,且有多种不同功能的实现
5. 竞争激烈的时候，lock有更好的性能

共同点：

1. 都是悲观锁，都支持互斥同步、锁重入、等待唤醒

#### sychorzined?

是java的一个关键字，是JVM提供的锁机制 可以保证原子性、可见性、有序性,是一种互斥同步  非公平,可重入，不可打断

底层实现是monitor(我们知道管程中只有一个线程能够运行)，代码编译后生成monitorenter 与 monitorexit 两个字节码指令(进入管程、退出管程) 

**注意：wait/notify等方法也依赖于monitor对象，所以只能在同步代码块中使用**

管程只能容纳一个线程进入运行 其他线程处于waiting状态 通过wait 和notify可以阻塞唤醒线程

使用：

​    1.修饰实例方法：当前对象实例加锁

​    2. 修饰静态方法：给当前类加锁，作用于类的所有实例对象

​    3.修饰代码块：参数可以指定加锁对象，如果指定的是类对象，表明对当前class加锁

#### 锁优化？

##### 自旋锁/自适应自旋

当线程获取不到锁时，为了减少上下文切换开销，不是立即阻塞，而是通过自选获取锁（默认10次）

根据线程获取锁的情况，决定这次自旋的时间

##### 锁消除

锁消除是指虚拟机即时编译器在运行时，对一些要求同步，但是对被检测到不可能存在竞争的共享数据竞争的锁进行消除。主要判断依据是逃逸分析。如果一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问，那么就可以把它作为栈上数据看待。

##### 锁粗化

将锁的范围扩大，以减少获取锁的次数。

##### 偏向锁

目的是消除数据在无竞争的时候的同步原语，进一步提升程序的运行性能。轻量级锁是在无竞争的情况下使用CAS操作消去同步互斥操作，偏向锁就是在无竞争的情况下，消除整个同步操作，连CAS也不需要了

偏向锁指这个锁会偏向于第一个获取它的线程，如果这个锁之后没有被其他线程获取，则持有的线程永远不需要同步。

设置偏向锁：偏向锁标志位为1 锁标志位为01 MW存储线程ID

如果有另一个线程来获取锁，则偏向模式结束，根据对象状态决定是否撤销偏向、锁状态是无锁还是轻量级锁。

对原持有偏向锁的线程进行撤销时，原获得偏向锁的线程有两种情况： 

1. 原获得偏向锁的线程如果已经退出了临界区，也就是同步代码块执行完了，那么这个时候会把对象头设置成无锁状态并且争抢锁的线程可以基于CAS重新偏向但前线程 

2. 如果原获得偏向锁的线程的同步代码块还没执行完，处于临界区之内，这个时候会把原获得偏向锁的线程升级为轻量级锁后继续执行同步代码块 

**注意：偏向锁下对象的hashcode不存储，如果对象已经计算过一致性哈希，则无法进入偏向模式，如果对象处于偏向模式，但是需要计算一致性哈希，则锁会膨胀为重量级锁**

##### 轻量级锁

在没有多线程竞争的前提下，减少传统重量级锁产生的性能消耗。

在代码没有进入同步块时，如果此同步对象没有被锁定，JVM首先在该线程的栈帧中建立一个lock record，存有对象markword的副本以及指向对象的指针；然后通过CAS操作长是把对象的MW更新为指向当前线程lock record的指针，如果成功了，则代表这个线程获得了轻量级锁，更新锁标志位为00；如果失败了，则代表至少存在一个线程竞争当前资源。虚拟机需要检查对象MW中的指针是否指向自己，如果是，则代表获得了锁，直接进入同步代码块，如果不是，则说明被抢占了。线程可以进行自选尝试获取锁，但是过多的尝试或者更多的线程竞争会使得锁升级为重量级锁。

轻量级锁的释放也是CAS操作完成。如果对象的MW仍然有指向线程的指针，则用CAS操作把当前对象的MW赋值回去，假如成功，则成功替换；否则说明有线程尝试过获取锁，就要在释放锁的同时，唤醒被挂起的线程。

##### 重量级锁

使用管程来实现的同步方式

#### AQS?

AQS是一个同步框架，它提供了一些操作来原子的管理同步状态，唤醒与阻塞线程，并管理一个因获取同步失败而封装成结点等待的同步队列。它是实现JUC中许多并发工具的同步组件的基础（可冲入锁、CountDownLatch等）。AQS的设计模式是模板方法模式，其内部已经定义好了完整的获取与释放锁的步骤，使用者通过继承AQS，并且实现它的抽象方法和空方法来实现自定义的同步管理方式。

我们先来看下内部的几个成员变量：

```
Node结点 用于存放等待线程的节点，一共有6种不同的状态，同时也有指向前后的指针
private volatile int state; 同步状态位，独占模式下为0表示资源空闲，>0表示有多少个线程在等待资源 共享模式下，这个值表示支持多少个线程同时获取锁，<0表示没有资源空闲
Node head,tail 表示队列的头部与尾部 队列的头部是一个虚节点，代表的线程并不在队列中了
```

##### 同步队列中节点的状态

SIGNAL:该节点的后继节点被(或即将被)阻塞(通过park)，因此当前节点释放或取消时必须解除后继节点的后继节点。

CANCELLED:节点因超时或中断被取消。节点变成这个状态后不会再改变，具有取消节点的线程也不会再次阻塞。

CONDITION:该节点当前处于条件队列中。在重新转移到同步队列之前，它不会被用作同步队列节点，而转移后结点状态将被设置为0。

PROPAGATE:应该将唤醒信号传播到后续节点。这是在doreleasshared中设置的(仅针对头节点)，以确保传播继续，即使其他操作已经介入。

0:以上均不设置。

数值按数字排列，以简化使用。非负值意味着节点不需要发出信号（唤醒其他结点）。所以，大多数代码不需要检查特定的值，只需要检查符号。对于正常同步节点，该字段初始化为0，对于条件节点，该字段初始化为CONDITION。它使用CAS修改(或者在可能的情况下，使用无条件的volatile写入)。

##### 同步队列

当前线程获取同步状态失败时，会将当前线程构造成一个结点加入同步队列尾部。

```java
    private Node addWaiter(Node mode) {
        Node node = new Node(Thread.currentThread(), mode);
        // 尝试快速入队
        Node pred = tail;
        if (pred != null) {
            node.prev = pred; // 当前结点的prev指向尾结点 注意这里是先连接的到上一个结点的指针
            if (compareAndSetTail(pred, node)) { //修改当前结点为尾结点
                pred.next = node; // 将上一个尾结点的next指向自己
                return node;
            }
        }
        // 在上述尝试快速入队失败后，进行这个方法，保证入队
        enq(node);
        return node;
    }
```

```java
    private Node enq(final Node node) {
        for (;;) { // 不断自旋 直到成功
            Node t = tail;
            if (t == null) { // 队列为空 需要初始化
                if (compareAndSetHead(new Node()))
                    tail = head;
            } else {
                node.prev = t;
                if (compareAndSetTail(t, node)) {
                    t.next = node;
                    return t;
                }
            }
        }
    }
```

同步器包含两个结点的引用，一个指向头结点，一个指向尾结点。首节点是获取到同步状态的结点，其在释放时会唤醒后继节点。后继节点会在自己获得同步状态时将自己设为头结点。

##### 独占式同步状态获取与释放

```java
public final void acquire(int arg) {
    //tryAcquire需要自己实现
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //添加到等待队列的线程尝试获取锁
        selfInterrupt(); //中断操作
}
```

```java
final boolean acquireQueued(final Node node, int arg) {
    // 当前结点被取消获取资源
    boolean failed = true; 
    try {
            // 返回值表示当前线程是否被中断过
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            // 如果当前结点的前驱结点是头结点 且获取同步状态成功
            if (p == head && tryAcquire(arg)) {
                setHead(node); 
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
                // 无法获取到同步的结点是否需要挂起 如果需要则park，返回值是park下是否被中断
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed) // 取消获取同步
            cancelAcquire(node);
    }
}
```

```java
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)  //前一个结点为signal 则当前线程可以安全的挂起
        return true;
    if (ws > 0) { //删去被取消的结点
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus > 0);
        pred.next = node;
    } else {
        //其他情况下将前一个结点设为signal状态 表明上一个结点刚刚初始化或者是共享模式的传递状态
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}
```

```
private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this); // 会阻塞在这里
    return Thread.interrupted(); // 返回中断位 并清空中断位
}
```

```java
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null && h.waitStatus != 0) //说明可能有结点需要唤醒
            unparkSuccessor(h);
        return true;
    } //未成功释放锁
    return false;
}
```

```java
private void unparkSuccessor(Node node) {
    int ws = node.waitStatus;
    if (ws < 0) //将头结点状态位设为0
        compareAndSetWaitStatus(node, ws, 0);

    //通常情况下唤醒下一个结点 如果有被取消的结点，则是第一个需要唤醒的结点（<0）
    Node s = node.next;
    if (s == null || s.waitStatus > 0) {
        s = null;
        for (Node t = tail; t != null && t != node; t = t.prev)
            if (t.waitStatus <= 0)
                s = t;
    }
    if (s != null)
        //唤醒
        LockSupport.unpark(s.thread);
}
```

**对于可中断、超时获取同步，基本算法差不多，但是如果中断位为true，则直接抛出中断异常，而不等到线程获取同步状态，同时还有超时的设置，超过时间则返回false**

##### 共享模式下获取与释放同步状态

共享模式指多个线程能够获取到同步状态，即多个线程可以一起运行。

```java
public final void acquireShared(int arg) {
    if (tryAcquireShared(arg) < 0) // 方法需要实现 如果小于0则没有获取到同步状态 需要加入队列
        doAcquireShared(arg);
}
```

```java
private void doAcquireShared(int arg) {
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                if (r >= 0) {
                    // 这里与独占模式不同 获取到同步状态的线程除了设置头结点外，还需要唤醒后面的线程
                    setHeadAndPropagate(node, r); 
                    p.next = null; // help GC
                    if (interrupted)
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

```java
private void setHeadAndPropagate(Node node, int propagate) {
    Node h = head; // Record old head for check below
    setHead(node);

        // 如果propagate大于0 说明还有资源，唤醒后续
        // 如果上一个头结点的ws小于0，这里我们思考下什么时候会小于0
        // 发现在调用doReleaseShared，head的值会被设置为负数（-3）
        // 也就是说是负数说明别的线程释放了资源，可以传递唤醒
    if (propagate > 0 || h == null || h.waitStatus < 0 ||
        // 当前头结点<0 说明后面有结点在等待，可以尝试唤醒
        (h = head) == null || h.waitStatus < 0) {
        Node s = node.next;
        if (s == null || s.isShared())
            doReleaseShared();
    }
}
```

```java
private void doReleaseShared() { // 因为同一时刻可能会有多个结点进行这个操作 需要CAS确保原子性
    for (;;) {
        Node h = head;
        if (h != null && h != tail) {
            int ws = h.waitStatus;
            if (ws == Node.SIGNAL) { // 说明后续结点需要唤醒
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;
                unparkSuccessor(h);
            }
            else if (ws == 0 && //后续结点暂时不需要唤醒，但是标记为propagate，表明这边已经释放了资源，唤醒可以传递下去（即使头结点的后继节点发现资源已经没有剩余了）
                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) 
                continue;                // loop on failed CAS
        }
        if (h == head)                   // 如果头结点改变了 说明有新的结点获得了同步状态 继续循环唤醒
            break;
    }
}
```

```java
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) { //释放锁成功
        doReleaseShared(); // 唤醒后续结点
        return true;
    }
    return false;
}
```

#### ReentrantLock？

实现了Lock接口，是JUC中的常用锁，功能丰富。

在并发编程中，它可以实现公平锁和非公平锁对共享资源进行同步

并且，reetrantlock支持可重入（只线程在获取了一个对象的锁后，仍可继续获取该对象的锁，但同时释放也需要释放所有的锁）， 在调度上更灵活，支持更多的功能（公平、多个等待条件）

那么它是如何实现锁的功能的呢？

看源码知道其内部含有一个继承自AQS的抽象类sync 还有两个他的实现类 分别对应于公平锁和非公平锁的实现

```java
abstract static class Sync extends AbstractQueuedSynchronizer {
    // 通过重写lock 到达非公平与公平
    abstract void lock();
    // 非公平获取 思考：为什么要放在抽象类里面？
    final boolean nonfairTryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) { // 说明可获取锁 非公平模式直接获取
            if (compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) { //不为0 因为支持可重入，如果锁的独占线程是自己则也可继续获取
            int nextc = c + acquires;
            if (nextc < 0) // overflow
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }

    // 释放锁
    protected final boolean tryRelease(int releases) {
        int c = getState() - releases;
        if (Thread.currentThread() != getExclusiveOwnerThread())
            throw new IllegalMonitorStateException();
        boolean free = false;
        if (c == 0) { // 锁全部释放
            free = true;
            setExclusiveOwnerThread(null);
        }
        setState(c);
        // 这里的返回值是当前线程是否已经完全释放了所有锁
        return free;
    }

}
```

​    syn类有两个final方法 

- nofairTryAcquire
  
  当state = 0 直接cas取锁
  
  不为0 ，那么如果当前锁是自己占有的，就可以继续获取锁，累加state return true 

- tryRelease
  
  释放当前资源的锁，返回值为当前资源的是否完全被释放

##### 公平锁的实现：

​    Lock：直接调用acquire（） FairSync重写了tryacquire，使他是公平模式的（就算当前资源s为0 但是fifo队列之前有其他等待线程，那么还是进入队列等待）

​    unlock 调用aqs中的release方法

```java
static final class FairSync extends Sync {
    final void lock() {
        acquire(1); // 这是AQS中的方法
    }
    protected final boolean tryAcquire(int acquires) { //模板方法模式的体现
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) { // 即时c是0 也需要判断是否是队列中的第一个元素（不含头）
            if (!hasQueuedPredecessors() &&
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) { // 自己是独占线程，则也可以获取到
            int nextc = c + acquires;
            if (nextc < 0)
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
}
```

##### 非公平锁的实现：

Lock :直接cas获取锁并设置当前资源的主人是自己 只会进行一次 没有成功则调用父类acquire（NofairSync重写了tryacquire方法 会先进行一次CAS获取）

unlock 调用aqs中的release方法

```java
static final class NonfairSync extends Sync {
    final void lock() {
        if (compareAndSetState(0, 1)) // 直接cas获取锁，非常简单粗暴
            setExclusiveOwnerThread(Thread.currentThread());
        else // 失败的话，使用AQS的acquire方法
            acquire(1);
    }

    protected final boolean tryAcquire(int acquires) {
        return nonfairTryAcquire(acquires); // 这里的tryAcquire是调用的父类的非公平获取
    }
}
```

然后我们再看看reentrantLock暴露给我们使用的方法

首先我们可以指定非公平锁还是公平锁，sync成员变量会赋值为对应的同步类对象

```
public void lock() {
    sync.lock(); // 调用同步器的lock方法
}
```

```
public boolean tryLock() {
    return sync.nonfairTryAcquire(1); // tryLock方法总是非公平获取
}
```

```
public void unlock() {
    sync.release(1);
}
```

#### ThreadPoolExecutor?

##### 线程池的优点：

池化技术主要通过资源的复用，减少每次获取资源的消耗，提高对资源的利用率。

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

##### 线程池的基本概念：

Worker:运行任务的内部结点

核心线程数：在阻塞队列未满时，最大的工作线程数

最大线程数：线程池最多允许多少个线程工作

阻塞队列：保存未分配工作线程的任务

拒绝策略：线程池决定以什么方式拒绝新任务进入线程池

保活时间：工作线程未分配任务后最大存活时间，如果允许核心线程超时，那么核心线程也会适用这个参数

##### 线程池的状态

TPE中有一个成员变量ctl，其高二位表示线程池的状态,低位表示工作线程数

running  （ctl 小于0）

shutdown 线程池不接受任务，但是仍然运行阻塞队列任务

stop  线程池不接受、停止运行任务

tidy 如果线程池与阻塞队列任务为空，则进入这个状态

terminated 线程池终止

##### 内部类Worker

继承了AQS,具有锁的功能（目的：工作线程在运行任务（s为1）、未运行任务前（s为-1）时，不可以被shutdown()操作中断。）

```
private final class Worker
    extends AbstractQueuedSynchronizer
    implements Runnable
```

```
public void run() {
    runWorker(this); //运行
}
```

```java
final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    Runnable task = w.firstTask;
    w.firstTask = null;
    w.unlock(); // Woker要开始运行任务了，此时允许被中断
    boolean completedAbruptly = true;
    try {          //循环从阻塞队列中获取任务
        while (task != null || (task = getTask()) != null) {// 如果当前有任务，就执行当前任务，否则从阻塞队列获取 getTask在超时和线程池关闭会返回null
            w.lock(); //获取锁，不允许被中断(注意这个中断的限制，后面terminate有说)
            if ((runStateAtLeast(ctl.get(), STOP) || // 当前线程池为stop
                 (Thread.interrupted() && // 当前线程已经中断（清除了标志位），线程池stop，最后再判断一下当前线程未被中断
                  runStateAtLeast(ctl.get(), STOP))) &&
                !wt.isInterrupted())
                wt.interrupt(); // 反正就是中断当前线程（标记）
            try { // 运行到这里表示需要执行任务
                beforeExecute(wt, task);
                Throwable thrown = null;
                try {
                    task.run(); //执行任务
                } catch (RuntimeException x) {
                    thrown = x; throw x;
                } catch (Error x) {
                    thrown = x; throw x;
                } catch (Throwable x) {
                    thrown = x; throw new Error(x);
                } finally {
                    afterExecute(task, thrown);
                }
            } finally {
                task = null;
                w.completedTasks++;
                w.unlock(); // 解锁
            }
        }
        completedAbruptly = false;
    } finally { // 如果获取任务失败（可能是线程池已经关闭）会执行这个 主要用于清理工作线程
        processWorkerExit(w, completedAbruptly);
    }
}
```

```java
private void processWorkerExit(Worker w, boolean completedAbruptly) { // 线程结束的一些处理工作
    // 如果completedAbruptly=false，说明是由getTask返回null导致的，WorkerCount递减的操作已经执行
    // 如果completedAbruptly=true，说明是由执行任务的过程中发生异常导致，需要进行WorkerCount递减的操作
    if (completedAbruptly) 
        decrementWorkerCount();

    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        completedTaskCount += w.completedTasks;
        workers.remove(w);
    } finally {
        mainLock.unlock();
    }

    tryTerminate(); // 也就是说每个工作线程最后结束的时候都会执行这个tryTerminate方法，与后文的加速终止呼应

    int c = ctl.get();
        // 如果是异常结束（completedAbruptly=true），需要重新调用addWorker()增加一个线程，保持线程数量
    // 如果是由getTask()返回null导致的线程结束，需要进行以下判断：
    //    1）如果allowCoreThreadTimeOut=true且队列不为空，那么需要至少保证有一个线程
    //    2）如果allowCoreThreadTimeOut=false,那么需要保证线程数大于等于corePoolSize
    if (runStateLessThan(c, STOP)) {
        if (!completedAbruptly) {
            int min = allowCoreThreadTimeOut ? 0 : corePoolSize;
            if (min == 0 && ! workQueue.isEmpty())
                min = 1;
            if (workerCountOf(c) >= min)
                return; // replacement not needed
        }
        addWorker(null, false);
    }
}
```

任务提交过程：

```java
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();

    int c = ctl.get();
    if (workerCountOf(c) < corePoolSize) { //1 工作线程数小于核心线程数，添加一个核心线程
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    if (isRunning(c) && workQueue.offer(command)) { // 2如果创建核心线程失败或者工作线程数大于核心线程数，则判断线程池是否是running 如果是则添加任务到阻塞队列
        int recheck = ctl.get();
        if (! isRunning(recheck) && remove(command)) // 如果添加到阻塞队列后线程池不是running状态，且成功移除了该任务，则触发拒绝策略
            reject(command);                       
        else if (workerCountOf(recheck) == 0) // 如果未移除任务且当前工作线程数为0 则添加一个非核心线程
            addWorker(null, false);
    }
    else if (!addWorker(command, false))  // 3 如果添加进阻塞队列失败，则尝试创建一个非核心线程，去运行这个任务
        reject(command);   // 4 如果失败则触发拒绝策略
}
```

```java
// 添加一个worker
private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    // 这个for循环，保证线程数不会超过限制（核心/最大），且保证合法的新增线程成功
    for (int c = ctl.get();;) {

        //这个是对线程池状态的检查 特殊状态不能创建新线程
        if (runStateAtLeast(c, SHUTDOWN)
            && (runStateAtLeast(c, STOP) // 如果是stop以上状态 不能创建新的
                || firstTask != null // 如果是shutdown状态，且提交的firstTask不是null，也不能创建
                || workQueue.isEmpty())) // 如果是shutdown状态，且队列为空，也不能创建
            return false;

        for (;;) {
        // 超过线程池线程最大数不能创建新线程
            if (workerCountOf(c)
                >= ((core ? corePoolSize : maximumPoolSize) & COUNT_MASK))
                return false;
            // 到这里说明可以创建
            if (compareAndIncrementWorkerCount(c)) //新增一个工作线程到ctl
                break retry;
            c = ctl.get();              // 由于线程数变化导致CAS失败，则继续内循环
            if (runStateAtLeast(c, SHUTDOWN))
                continue retry;

        }
    }
    // 运行到这里真正创建工作线程
    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        w = new Worker(firstTask);
        final Thread t = w.thread;
        if (t != null) {
        // 加锁更新workers
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock(); // 这里加锁是为了更新set里面的值
            try {
                    int c = ctl.get();
                    int rs = runStateOf(ctl.get());
                    if (rs < SHUTDOWN || //再次检查状态
                        (rs == SHUTDOWN && firstTask == null)) {
                        if (t.isAlive()) // 一个保障检查吧，确保t线程还存活
                            throw new IllegalThreadStateException();
                        workers.add(w);
                        int s = workers.size();
                        if (s > largestPoolSize)
                            largestPoolSize = s;
                        workerAdded = true;
                    }
            } finally {
                mainLock.unlock();
            }
            // 运行任务
            if (workerAdded) {
                t.start(); // 启动线程
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
            addWorkerFailed(w);
    }
    return workerStarted;
}
```

##### 几大拒绝策略

拒绝策略指任务加入线程池失败时的处理策略，是实现了`RejectedExecutionHandler`接口的内部类，我们也可以自己实现。

主要有四个拒绝策略

1、AbortPolicy   

当任务添加到线程池中被拒绝时，它将抛出 RejectedExecutionException 异常。（该策略下，直接丢弃任务，并抛出RejectedExecutionException异常）

2、DiscardPolicy

当任务添加到线程池中被拒绝时，默认情况下它将丢弃被拒绝的任务。（即该策略下，直接丢弃任务，什么都不做）

3、DiscardOldestPolicy

当任务添加到线程池中被拒绝时，线程池会放弃等待队列中最旧的未处理任务，然后将被拒绝的任务添加到等待队列中。

（该策略下，抛弃进入队列最早的那个任务，然后尝试把这次拒绝的任务放入队列）

4、CallerRunsPolicy

不进入线程池执行，在这种方式（CallerRunsPolicy）中，任务将由调用者线程去执行。

（用于被拒绝任务的处理程序，它直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务。）

##### shutdown() 与 shutdownNow()的区别

shutdown会使线程池进入shutdown状态，同时会中断未运行任务的工作线程，然后等待所以工作中的线程完成任务和阻塞队列中的任务后，会执行`processWorkerExit`方法(这个方法调用`tryTerminated()`)，当所以线程都中断了之后，就会进入tidy->terminated

shutdownNow 线程池进入stop状态，中断所有启动的任务线程，调用`tryTerminated`，返回剩余任务列表

中断全部已经开始的线程与中断为运行的空闲线程的区别在于：前者不需要获取worker的同步位（但是会判断同步位是否小于1，区别于未开始的线程）后者需要tryLock()获取同步位之后中断

```java
public void shutdown() {
    final ReentrantLock mainLock = this.mainLock; // 获取全局锁，有了锁后，同一时间只会有一个shutdown运行，且新的worker不能在建立
    mainLock.lock();
    try {
        checkShutdownAccess(); // 判断是否有权终止
        advanceRunState(SHUTDOWN); // 设置状态位为SHUTDOWN
        interruptIdleWorkers(); // 中断所有空闲线程
        onShutdown(); // hook for ScheduledThreadPoolExecutor
    } finally {
        mainLock.unlock(); // 释放全局锁
    }
    tryTerminate(); //尝试终止线程池
}
```

```java
public List<Runnable> shutdownNow() {
    List<Runnable> tasks;
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        checkShutdownAccess();
        advanceRunState(STOP); // 更改状态位为STOP
        interruptWorkers();
        tasks = drainQueue(); //获取阻塞队列中的任务
    } finally {
        mainLock.unlock();
    }
    tryTerminate();
    return tasks;
}
```

这两个方法最后都调用了tryTerminated方法，我们一起来看一下

```java
final void tryTerminate() {
    for (;;) {
        int c = ctl.get();
        if (isRunning(c) || //正在运行
            runStateAtLeast(c, TIDYING) || //已经进入tidying或者terminated状态
            (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty())) // 已经shutdown且队列不为空
            return; // 满足上述条件，则还不能终止，直接返回
        if (workerCountOf(c) != 0) { // 运行到这里，说明线程池的状态为shutdown且队列空 或者 stop,这时候会中断一个空闲的工作线程，促进终止
            interruptIdleWorkers(ONLY_ONE); // 至于为什么说会促进终止，可以看runWorker（）方法的最后
            return;
        }
        // 运行到这里，说明线程池里面已经没有工作线程了，并且线程池的状态为shutdown或者stop
        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock(); // 加锁
        try {
            if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { // 将当前状态设置为TIDYING 如果cas失败，则下一次循环
                try {
                    terminated(); //空方法
                } finally {
                    ctl.set(ctlOf(TERMINATED, 0)); //设置状态为TERMINATED
                    termination.signalAll(); //唤醒等待在termination上的线程
                }
                return;
            }
        } finally {
            mainLock.unlock();
        }
        // else retry on failed CAS
    }
}
```

#### JUC中的几个ATOMIC类

为各种数据类型的对象提供了原子操作。

内部有一个Unsafe对象，大部分方法调用了unsafe的方法实现原子性。

#### CountDownLatch的基本概念

相当于一个倒计时器，一开始设置好计时数，然后每到一种情况可以触发，计时数就减一，直到为0

内部实现是基于AQS共享模式的，state的值设置为count

当有线程调用countDown()时，state的值会减一（不会小于0）

线程调用await方法会以共享模式获取同步状态，如果此时state不为0，则获取失败，加入同步队列。多个线程都可以调用await方法，因为是同步队列。

注意这里获取同步位成功并不会修改同步位的值，也就是说在同步位被释放到0后，所有等待的线程都可以获取到同步位了，这也符合这个类的设计思想

```java
    public void await() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }


public void countDown() {
    sync.releaseShared(1);
}
```

#### CopyOnWriteArrayList基本概念

在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问 `List` 的内部数据，毕竟读取操作是安全的。

`CopyOnWriteArrayList` 读取是完全不用加锁的，并且更厉害的是：写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待。这样一来，读操作的性能就会大幅度提升。

`CopyOnWriteArrayList` 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。

因为对数组的修改会先赋值数组的副本，在副本上修改，最后赋值给变量，所以读取不需要加任何锁。

而写入add（）等是需要加锁的，主要是防止多个写入操作生成多个数组副本，但是与读可以同时进行，互不干扰

注意，cowa是fail-safe的

#### ThreadLocal的基本概念

ThreadLocal起到了变量线程隔离的作用，`ThreadLocal`对象可以提供线程局部变量，每个线程`Thread`拥有一份自己的**副本变量**，多个线程互不干扰。

`Thread`类有一个类型为`ThreadLocal.ThreadLocalMap`的实例变量`threadLocals`，也就是说每个线程有一个自己的`ThreadLocalMap`。

`ThreadLocalMap`有自己的独立实现，可以简单地将它的`key`视作`ThreadLocal`，`value`为代码中放入的值

每个线程在往`ThreadLocal`里放值的时候，都会往自己的`ThreadLocalMap`里存，读也是以`ThreadLocal`作为引用，在自己的`map`里找对应的`key`，从而实现了**线程隔离**。

#### 为什么ThreadLocal会造成内存泄漏？

ThreadLocalMap中存放的对象是Entry，它继承自WeakReference 节点的key是弱引用，而value是强引用。如果说key（ThreadLocal对象）没有被其他强引用引用，那么在下一次垃圾回收的时候，vm会回收key，但是value并不会被回收，即使它没有被其他引用引用。这个时候就会造成内存泄漏。所以如果想要移除map中的对象，需要使用remove方法.

#### ThreadLocal应用场景？

1. 每个线程内需要保存全局变量（例如在拦截器中获取用户信息），可以让不同方法直接使用，避免参数传递的麻烦。
2. 每个线程需要一个独享的对象（通常是工具类，典型需要使用的类有SimpleDateFormat和Random）

#### ConcurrentHashMap

##### sizeCtl变量

这个变量是用于控制表初始化和resize 当为-1时，表示table正在初始化，如果是不为-1的负数，表示正在resize，且值表示-(1+正在运行的进行reszie的线程);当表为null时，表示初始的表的大小;在初始化后，表示下一次要resize的大小。

ForwardingNode 特殊结点，表示当前桶的元素已经全部迁移到新桶了

nextTab 暂存未完成扩容后数据迁移的新表

```java
// get方法与hashmap差不多
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    int h = spread(key.hashCode()); // 计算hash
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (e = tabAt(tab, (n - 1) & h)) != null) {
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.val;
        }
        else if (eh < 0) // 这里表示是特殊Node(-1 forwardingNode -2 tree的root)
            return (p = e.find(h, key)) != null ? p.val : null;
        while ((e = e.next) != null) { // 否则就是正常的遍历搜索
            if (e.hash == h &&
                ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
```

```java
//put方法变化比较大
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) { // 相当于轮询操作
        Node<K,V> f; int n, i, fh;
        if (tab == null || (n = tab.length) == 0)
            tab = initTable(); // 如果tab还没有初始化 则初始化tab
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            if (casTabAt(tab, i, null, // 如果桶里面还没有元素 那么cas直接put进去
                         new Node<K,V>(hash, key, value, null)))
                break;  // 如果成功放入则跳出循环
        }
        else if ((fh = f.hash) == MOVED) // 如果当前桶的元素已经迁移到新桶了
            tab = helpTransfer(tab, f); // 这里当前线程帮助扩容移动元素,返回新tab
        else {
            V oldVal = null;
            synchronized (f) { // 当前桶有元素、且元素并没有迁移完，加锁把元素插入
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) {
                        binCount = 1;
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i); //超过阈值 树化
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
```

```java
// 初始化表 保证只初始化一次
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        if ((sc = sizeCtl) < 0)//说明已经在进行初始化或者扩容了
            Thread.yield(); //让出cpu 
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {// 设置sizeCtl值为-1 获取到初始化权利
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    sc = n - (n >>> 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

### 设计模式

简介：

> 设计模式，是指在软件设计中，被反复使用的一种代码设计经验。使用设计模式的目的是为了可重用代码,降低代码耦合度，提高代码的可扩展性和可维护性。

遵循原则：

- 里氏替换原则
  - 如果对一个父类的方法调用能够成功，则调用子类的同方法也要成功
- 开闭原则
  - 对扩展开放，对修改关闭

#### 创建型模式

##### 简单工厂模式

##### 静态工厂模式

直接通过静态方法返回创建的对象

##### 工厂方法模式

工厂方法的目的是使得创建对象和使用对象是分离的，并且客户端总是引用抽象工厂和抽象产品

![image-20220716104735804](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220716104735804.png)

给工厂接口一个getFactory方法，用于获取工厂的真正实现类，实现类调用方法返回创建的对象，如下，NumberFactory和Number都是抽象类，我们使用时完全忽略了实现类，从而允许创建产品的代码独立地变换，而不会影响到调用方。

```
NumberFactory factory = NumberFactory.getFactory();
Number result = factory.parse("123.456");
```

##### 抽象工厂模式

抽象工厂模式和工厂方法不太一样，它要解决的问题比较复杂，不但工厂是抽象的，产品是抽象的，而且有多个产品需要创建，因此，这个抽象工厂会对应到多个实际工厂，每个实际工厂负责创建多个实际产品

![image-20220716110315832](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220716110315832.png)

即，有一个基础的抽象工厂接口，这个接口提供几种创建不同类别产品的方法，同时，考虑到不同厂商（即抽象工厂接口的实现类）对产品的实现方式各不相同，它也有一个方法获得对应的实现工厂。这样，在使用时，我们先通过抽象工厂获得对应的具体工厂，然后通过具体的工厂获得我们需要的产品。

```java
public interface AbstractFactory {
    public static AbstractFactory createFactory(String name) {
        if (name.equalsIgnoreCase("fast")) {
            return new FastFactory();
        } else if (name.equalsIgnoreCase("good")) {
            return new GoodFactory();
        } else {
            throw new IllegalArgumentException("Invalid factory name");
        }
    }
        // 创建Html文档:
    HtmlDocument createHtml(String md);
    // 创建Word文档:
    WordDocument createWord(String md);
}
```

```
// Html文档接口:
public interface HtmlDocument {
    String toHtml();
    void save(Path path) throws IOException;
}

// Word文档接口:
public interface WordDocument {
    void save(Path path) throws IOException;
}
```

```
public class FastFactory implements AbstractFactory {
    public HtmlDocument createHtml(String md) {
        return new FastHtmlDocument(md);
    }
    public WordDocument createWord(String md) {
        return new FastWordDocument(md);
    }
}
```

##### 原型模式

原型模式，即Prototype，是指创建新对象的时候，根据现有的一个原型来创建。

即根据现有对象，创建一个一模一样的新对象

##### 单例模式

单例模式（Singleton）的目的是为了保证在一个进程中，某个类有且仅有一个实例。

实现方式：懒加载、静态内部类加载、饿汉

```java
/**
 * 懒加载 单线程的单例模式 多线程下不安全
 * */
//class Singleton{
//    private Singleton(){
//    }
//    private static Singleton instance = null;
//    public static Singleton getInstance(){
//        if (instance == null){
//            instance = new Singleton();
//        }
//        return instance;
//    }
//}

/**
 * 线程安全的懒加载单例模式
 * */
//class Singleton{
//    private Singleton(){
//    }
//    private static volatile Singleton instance = null;  // 指令可能重排序 另一个线程可能返回一个未初始化的对象
//    public static Singleton getInstance(){
//        if (instance == null){
//        synchronized (Singleton.class) {
//            if (instance == null) {  // 双重检锁
//                instance = new Singleton();
//            }
//        }
//        }
//        return instance;
//        }
//    }

/***
 * 静态内部类不会在程序启动的时候加载 
 * 所以只有在第一次调用get时候，对象才会被创建
 */
class Singleton{
    private Singleton(){
    }
    private static class SingletonHolder{
        private static final Singleton instance = new Singleton(); 
    }
    public static Singleton getInstance(){
        return SingletonHolder.instance;
    }
}
```

##### 生成器模式(Builder)

生成器模式（Builder）是使用多个“小型”工厂来最终创建出一个完整对象。

当我们使用Builder的时候，一般来说，是因为创建这个对象的步骤比较多，每个步骤都需要一个零部件，最终组合成一个完整的对象。

常见的builder使用是链式调用，先设置一些参数，然后通过build()方法生成对象

```
String url = URLBuilder.builder() // 创建Builder
        .setDomain("www.liaoxuefeng.com") // 设置domain
        .setScheme("https") // 设置scheme
        .setPath("/") // 设置路径
        .setQuery(Map.of("a", "123", "q", "K&R")) // 设置query
        .build(); // 完成build
```

#### 结构型模式

##### 适配器模式

适配器模式是Adapter，也称Wrapper，将一个类的**接口**转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。

编写一个Adapter的步骤如下：

1. 实现目标接口，这里是`Runnable`；
2. 内部持有一个待转换接口的引用，这里是通过字段持有`Callable`接口；
3. 在目标接口的实现方法内部，调用待转换接口的方法。

```
public class RunnableAdapter implements Runnable {
    // 引用待转换接口:
    private Callable<?> callable;

    public RunnableAdapter(Callable<?> callable) {
        this.callable = callable;
    }

    // 实现指定接口:
    public void run() {
        // 将指定接口调用委托给转换接口调用:
        try {
            callable.call();
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }
}
```

##### 桥接模式

使用组合而非继承的方式表示对象，将抽象部分与它的实现部分分离，使它们都可以独立地变化。

可以避免直接继承带来的子类爆炸

![image-20220716153703731](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220716153703731.png)

上图是传统的使用继承来表示

![image-20220716153731802](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220716153731802.png)

上图是桥接模式

桥接模式实现比较复杂，实际应用也非常少，但它提供的设计思想值得借鉴，即不要过度使用继承，而是优先拆分某些部件，使用组合的方式来扩展功能。

##### 组合模式

将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。

在XML或HTML中，从根节点开始，每个节点都可能包含任意个其他节点，这些层层嵌套的节点就构成了一颗树。

![image-20220716162147954](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220716162147954.png)

```
public interface Node {
    // 添加一个节点为子节点:
    Node add(Node node);
    // 获取子节点:
    List<Node> children();
    // 输出为XML:
    String toXml();
}
```

```
// 元素结点 可以作为容器包含其他结点
// 此外 还有注释结点、文本结点等
public class ElementNode implements Node {
    private String name;
    private List<Node> list = new ArrayList<>();

    public ElementNode(String name) {
        this.name = name;
    }

    public Node add(Node node) {
        list.add(node);
        return this;
    }

    public List<Node> children() {
        return list;
    }

    public String toXml() {
        String start = "<" + name + ">\n";
        String end = "</" + name + ">\n";
        StringJoiner sj = new StringJoiner("", start, end);
        list.forEach(node -> {
            sj.add(node.toXml() + "\n");
        });
        return sj.toString();
    }
}
```

##### 装饰器模式

装饰器（Decorator）模式，是一种在运行期动态给某个对象的实例增加功能的方法。

即将对象包装一下，具有更多的功能，它把对象的核心功能与附加功能分离，方便拓展。

![image-20220716163333863](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220716163333863.png)

如果我们要新增核心功能，就增加Component的子类，如果我们要增加附加功能，就增加Decorator的子类。

下图就是一种装饰模式

![image-20220716163414788](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220716163414788.png)

下面举一个渲染html文本的例子，他的核心功能是渲染页面，但是也可以有加粗文本等功能。

```
public interface TextNode {
    // 设置text:
    void setText(String text);
    // 获取text:
    String getText();
}

//核心功能实现类
public class SpanNode implements TextNode {
    private String text;

    public void setText(String text) {
        this.text = text;
    }

    public String getText() {
        return "<span>" + text + "</span>";
    }
}
```

```java
//装饰器类
public abstract class NodeDecorator implements TextNode {
    protected final TextNode target;

    protected NodeDecorator(TextNode target) {
        this.target = target;
    }

    public void setText(String text) {
        this.target.setText(text);
    }
}
public class BoldDecorator extends NodeDecorator {
    public BoldDecorator(TextNode target) {
        super(target);
    }

    public String getText() {
        return "<b>" + target.getText() + "</b>";
    }
}
```

##### 外观模式

> 外观模式，即Facade，是一个比较简单的模式。它的基本思想如下：
> 
> 如果客户端要跟许多子系统打交道，那么客户端需要了解各个子系统的接口，比较麻烦。如果有一个统一的“中介”，让客户端只跟中介打交道，中介再去跟各个子系统打交道，对客户端来说就比较简单。所以Facade就相当于搞了一个中介。

**即，为系统中的一组接口提供一个高层接口，这个接口调用子系统接口功能，用户无需知道具体实现细节，使得子系统更加容易使用**

更复杂的Web程序，会有多个Web服务，这个时候，经常会使用一个统一的网关入口来自动转发到不同的Web服务，这种提供统一入口的网关就是Gateway，它本质上也是一个Facade，但可以附加一些用户认证、限流限速的额外服务。

##### 代理模式

为其他对象提供一个代理以控制对这个对象的访问，同时也能增强对象的方法。

好处：职责清晰：一个类只负责一件事，通过代理我们可以获得更加简洁清晰的代码。

常见使用：JDBC连接的懒加载、连接池

##### 享元模式

如果一个对象实例一经创建就不可变，那么反复创建相同的实例就没有必要，直接向调用方返回一个共享的实例就行，这样即节省内存，又可以减少创建对象的过程，提高运行速度。

享元模式在Java标准库中有很多应用。我们知道，包装类型如`Byte`、`Integer`都是不变类，因此，反复创建同一个值相同的包装类型是没有必要的。以`Integer`为例，如果我们通过`Integer.valueOf()`这个静态工厂方法创建`Integer`实例，当传入的`int`范围在`-128`~`+127`之间时，会直接返回缓存的`Integer`实例，对于`Byte`全部都是缓存对象

在实际应用中，享元模式主要应用于缓存，即客户端如果重复请求某些对象，不必每次查询数据库或者读取文件，而是直接返回内存中缓存的数据。

#### 行为型模式

##### 责任链模式

责任链模式（Chain of Responsibility）是一种处理请求的模式，它让多个处理器都有机会处理该请求，直到其中某个处理成功为止。责任链模式把多个处理器串成链，然后让请求在链上传递

![image-20220716165908642](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220716165908642.png)

常见应用：拦截器、过滤器

##### 命令模式

![image-20220716170257965](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220716170257965.png)

命令模式（Command）是指，把请求封装成一个命令，然后执行该命令。

即客户调用命令对象，有命令对象的execute执行相应的方法。

##### 迭代器模式

提供一种方法顺序访问一个聚合对象中的各个元素，而又不需要暴露该对象的内部表示。

在JAVA的集合类中广泛使用

实际应用时，如果考虑到多线程访问，当一个线程正在迭代某个集合，而另一个线程修改了集合的内容时，是否能继续安全地迭代，还是抛出`ConcurrentModificationException`，就需要更仔细地设计。

##### 观察者模式

观察者模式（Observer）又称发布-订阅模式（Publish-Subscribe：Pub/Sub）。它是一种通知机制，让发送通知的一方（被观察方）和接收通知的一方（观察者）能彼此分离，互不影响。观察者模式就是要分离被观察者和观察者之间的耦合关系。

```
public class Store {
    private List<ProductObserver> observers = new ArrayList<>();
    private Map<String, Product> products = new HashMap<>();

    // 注册观察者:
    public void addObserver(ProductObserver observer) {
        this.observers.add(observer);
    }

    // 取消注册:
    public void removeObserver(ProductObserver observer) {
        this.observers.remove(observer);
    }

    public void addNewProduct(String name, double price) {
        Product p = new Product(name, price);
        products.put(p.getName(), p);
        // 通知观察者:
        observers.forEach(o -> o.onPublished(p));
    }

    public void setProductPrice(String name, double price) {
        Product p = products.get(name);
        p.setPrice(price);
        // 通知观察者:
        observers.forEach(o -> o.onPriceChanged(p));
    }
}
```

##### 备忘录模式

备忘录模式（Memento），主要用于捕获一个对象的内部状态，以便在将来的某个时候恢复此状态。

##### 状态模式

状态模式（State）经常用在带有状态的对象中。根据状态改变对象的行为，通常关键在于状态的改变。

##### 策略模式

策略模式：Strategy，是指，定义一组算法，并把其封装到一个对象中。然后在运行时，可以灵活的使用其中的一个算法。

策略模式的核心思想是在一个计算方法中把容易变化的算法抽出来作为“策略”参数传进去，从而使得新增策略不必修改原有逻辑。

##### 模板方法模式

定义一个操作的一系列步骤，对于某些暂时确定不下来的步骤，就留给子类去实现好了，这样不同的子类就可以定义出不同的步骤。

常见实现：JUC的AQS抽象类

##### *访问者模式

表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。

访问者模式的核心思想是为了访问比较复杂的数据结构，不去改变数据结构，而是把对数据的操作抽象出来，在“访问”的过程中以回调形式在访问者中处理操作逻辑。如果要新增一组操作，那么只需要增加一个新的访问者。

##### *中介模式

用一个中介对象来封装一系列的对象交互。中介者使各个对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。

##### 解释器模式（Parser）

给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。

### Linux/OS

#### 什么是操作系统

操作系统是管理计算机硬件与软件资源的程序，是计算机的基石。其核心是内核，负责系统的内存、硬件设备、文件系统与应用程序的管理

#### 系统调用/用户态与内核态

我们知道如果能够让应用程序随意的使用内存空间，是一件非常危险的事，如果破坏了操作系统程序，那么系统就会崩溃，所以，一般会把指令按照优先级分类（linux分为两类），高优先级的指令必须要在内核态才能进行，而普通指令在用户态就可以进行。

那如果我们程序需要去调用os的功能，那么就要调用系统调用，相当于一个trap，主动把cpu的控制权交给内核，由内核帮我们去完成操作。

#### 常用命令

###### grep

在文件中搜索指定内容 也可以用 | 管道的形式搜索前一个命令的输出

-i 忽略大小写

“？”可替代单个字符。

“*”可替代任意多个字符。

方括号“[charset]”可替代 charset 集中的任何单个字符，如[a-z]，[abABC]

###### ps

查看进程状态

`ps -aux `

`ps-ef`

###### kill

结束进程 pid

-1 重新加载进程

-9 强制杀死进程

-15 正常停止进程（默认）

###### ls

-a 显示所有文件

-l 显示详细信息

###### chmod

-r 递归给directory下的所有文件和子目录分配权限

###### 查看文件内容

vi 文件名 #编辑方式查看，可修改

cat 文件名 #显示全部文件内容

more 文件名 #分页显示文件内容

less 文件名 #与 more 相似，更好的是可以往前翻页

tail 文件名 #仅查看尾部，还可以指定行数

head 文件名 #仅查看头部,还可以指定行数

###### 日志动态查看

```
sudo tail -F /``var``/log/apache2/access.log
```

###### echo

输出后面的内容到终端

###### find

```
find   path   -option   [   -print ]   [ -exec   -ok   command ]   {} \;
```

-exec 参数后面跟的是command命令，它的终止是以;为结束标志的，所以这句命令后面的分号是不可缺少的，考虑到各个系统中分号会有不同的意义，所以前面加反斜杠。
{} 花括号代表前面find查找出来的文件名。

-ok 表示询问

查找还有`whereis`

###### ifconfig

查看ip地址

###### df

查看磁盘使用空间

-h 方便人阅读

-l  显示本地文件系统

###### free

查看内存信息

-m 以MB为单位

-h 易于阅读

###### 黑洞文件

- /dev/null 表示空设备文件 不可以读取 可以无限写入
- 0 表示stdin标准输入
- 1 表示stdout标准输出
- 2 表示stderr标准错误

###### 根目录与主目录

根目录是/ 是树状目录的根 只有一个

主目录是home/user目录 对于不同目录 主目录是不一样的

root用户缺省HOME目录是/root

#### 文件系统

概念：是一种数据结构，提供一种对操作系统和计算机用户的数据和程序的存储与访问机制

##### 磁盘的低级格式化与高级格式化？

低级格式化是给磁盘分块（磁盘分块中有head data tail三部分）

高级格式化是建立文件系统 不同操作系统不同       

##### 文件类型？

文件类型用于指示文件的内部结构，OS通过了解文件类型决定对文件如何进行解释

Unix系统只解释二进制可执行文件与文本文件，其他文件交给应用程序解释

**文件的基本分配单位：簇 簇的大小基于操作系统**

簇是一组物理块构成的集合，如果以簇作为分配单位，可以节省链接分配的指针占用空间比例

##### 文件的内部结构

文件由逻辑记录（Unix通常以一个字节为单位）组成，文件的存储方式有：

- 将逻辑文件打包后存入硬盘，取出后拆包

##### 文件的访问

- 顺序访问（要求逻辑记录顺序存储）**磁带模型**
- 直接访问（要求逻辑记录长度固定 连续存储）可按任意顺序快速访问 **磁盘模型**
- 索引访问

##### 文件目录

目录是一个符号表，将文件名与entriy对应起来

entry应包含： 文件基本属性、存放位置、访问权限  /或者是子目录（即**FCB**，unix中FCB称为INODE）

##### INODE 索引结点

inode 中包含文件的类型、访问控制表、硬链接数量、用户id、组id、字节数量等信息

同时还包含了一个15个block的地址数组，

single indirect 存放以及索引

double indirect 存放二级索引

还有三级索引

##### 文件分配方式

- 连续内存分配

- 链接内存分配 使用簇来优化链接占比

- 文件分配表FAT 用一张表来记录文件占用物理块号的顺序

- 索引分配 将文件物理块的顺序保存到索引表

##### 目录结构

- 单级目录 
- 两层目录 每个用户有自己的目录（UFD），用户的信息放在MFD（第一层）
- 树形目录 由树状结构组织的目录 每个目录文件下允许创建子目录

##### 用户与组

在多用户系统中，提出了文件共享和保护的需求

每个文件和目录关联一个ACL 访问控制表 有9个bit指示访问控制权限

- User 用户 所有者

- Group 用户集合 拥有相同的访问权限

- Other 其他用户

##### 硬链接与软连接

硬链接：两个用户的文件目录中指向同一个inode结点

软连接（符号链接）：创建一个Link文件，文件中包含共享文件的路径名，通过路径找到共享文件。

### 计算机网络

**奈氏准则** : 在任何信道中，码元的传输的效率是有上限的，传输速率超过此上限，就会出现严重的码间串扰问题，使接收端对码元的判决（即识别）成为不可能。

**香农定理** ：在带宽受限且有噪声的信道中，为了不产生误差，信息的数据传输速率有上限值。

##### OSI七层模型？

物理层、数据链路层、网络层、传输层、会话层、表示层、应用层

##### TCP/IP四层模型

- 网络接口层 **透明传输、封装成帧**

- 网络互连层 **路由选择、分组交换**

- 传输层 **传输层的主要任务就是负责向两台终端设备进程之间的通信提供通用的数据传输服务**

- 应用层  **应用层位于传输层之上，主要提供两个终端设备上的应用程序之间信息交换的服务，它定义了信息交换的格式，消息会交给下一层传输层来传输**

##### 各层的数据交换设备

- 网关：应用层、传输层（网关在传输层上以实现网络互连 ，仅用于两个高层协议不同的网络互连，也可以实现安全、过滤等功能。网关的结构也和路由器类似，不同的是互连层。
- 路由器：网络层（路由选择、存储转发） 隔离广播域
- 交换机（网桥的集合）：数据链路层（识别数据包中的 MAC 地址信息，根据 MAC 地址进 行转发，并将这些 MAC 地址与对应的端口记录在自己内部的一个地址表中） 、网桥：数据链路层（将两个 LAN 连起来，根据 MAC 地址来转发帧） **隔离冲突域** 独享带宽
- 集线器（多口中继器）（Hub）：物理层（纯硬件设备，主要用来连接计算机等网络终端）、中继器：物理层（在比特级别对网络信号进行再生和重定时，从而使得它们能够在 网络上传输更长的距离） **无法隔离冲突域**共享带宽

##### ARP协议（网络层）

ARP协议用于通过主机的ip地址，获得对应的mac地址

每个主机上都有一个 ARP 的高速缓存，可以提高ARP解析地址的效率。

过程：

1. 通过广播发送一个ARP请求包 包含目标IP地址 但是缺少MAC地址
2. 如果节点的IP地址与目的IP地址相同，则填入MAC，发送响应（对于不在一个网络中的数据，MAC地址为源主机同网络路由器的MAC地址）
3. 存入ARP高速缓存

##### ARP协议的弱点

1. 有缓存机制 更新延时
2. 可以伪装ARP应答

##### ARP代理

若 ARP 请求是从一个网络的主机发送给另一个网络上的主机，那么连接这两个网络的路由 器就可以回答该请求，这个过程叫做 ARP 代理。

ARP 代理路由器响应 ARP 请求的 MAC 地 址为路由器的 MAC 地址而非 ARP 请求的主机的 MAC 地址。

##### 免费ARP

指主机发送ARP查找自己的IP地址，即目的IP是主机的IP地址，它不需要得到回应，只为了告诉其他计算机自己的 IP 地址和 MAC 地址

- 一个主机使用免费 ARP 确定是有存在有其他主机设置了相同的 IP 地址 
- 如果发送免费 ARP 的主机改变了 MAC 地址，可以通过发送免费 ARP 的方式告知其他主机端更新 ARP 表

##### MTU最大值与最小值

64B-1500B

##### IPv4报文格式与字段含义

![image-20220712214628974](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220712214628974.png)

##### IP路由选择的过程

根据最长匹配原则，从路由表中找到条目，发送到指定的路由器。如果不能找到，如果有默认路由则从默认路由发出，否则返回一个“主机不可 达”或“网络不可达”的错误。

##### PING命令的实现协议

依托于ICMP差错报文实现的，用于检查目的主机能否联通、延迟情况

过程：

1. 发起ping请求
2. 发送ARP请求 查询对应的MAC地址
3. 目的主机响应ARP请求
4. 进行真正的PING请求（4次）

##### UDP与TCP的区别

**区别总结：**

1. UDP面向数据报,对上层数据既不合并也不拆分，TCP面向字节流

2. UDP不可靠，尽最大努力交付;TCP可靠，需要建立连接，且有有流量控制、拥塞控制等机制

3. UDP支持多对多、一对一、一对多，而TCP只支持点对点

4. UDP速度更快，TCP消耗的资源更多。
- UDP 是一个简单的面向数据报的运输层协议：进程的每个输出操作都正好产生一个 UDP 数 据报，并组装成一份待发送的 IP 数据报。UDP首部长度小，不可靠，无连接，无流量控制与拥塞控制，速度快，适用于实时通信。

![](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220712220541332.png)

​    **校验和计算**：

​    4字节对齐，源IP+目的IP +协议类型（前补0填充至2字节）+ UDP长度 /伪首部/ +双端口号+UDP长度+空校验和+数据+填充字节 **按二进制反码求和，然后取反码即为校验和**

- TCP 是面向流字符传输，传送的每一个数据单元是报文段，可靠、需要建立连接，一对一传输，且有拥塞控制与流量控制，适用于要求可靠性较高的应用。

![image-20220713131908383](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220713131908383.png)

部分字段的解释：

**序号**：占 4 字节。本报文段所发送的数据的第一个字节的序号。

**确认号**：占 4 字节，是期望收到对方下一个报文段的第一个数据字节的序号。

**数据偏移**：占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。 首部长度范围 20B-60B

**窗口**：占 2 字节。窗口指的是发送本报文段的一方的接收窗口大小。

**紧急指针**：占 2 字节。紧急指针仅在 URG = 1 时才有意义，它指出本报文字段中的紧急数据的字节数（紧急数据之后就是普通数据）。

**几个状态位**：

- ACK 确认
- SYN 建立连接时同步序号
- PUSH 表示希望立即接收到响应 不必等待缓存满再交付。（发送方立即发出，接收方立即交付应用程序）
- URG 表示数据中有紧急数据 插队发出
- FIN 释放连接
- RST 复位，表示TCP连接出现严重错误，必须是释放连接

**选项**：可选，不定长

- **最大报文段长度 MSS** 默认556B
- **窗口扩大选项**
- **时间戳选项**
- **选择确认（SACK）**

##### TCP如何保证可靠性？

1. 应用数据被分割成 TCP 认为最适合发送的数据块。
2. 确认机制，发送报文后，等待确认。 
3. 重发机制，没有收到确认，将重发数据段。
4. 保持它首部和数据的校验和。确认数据的准确性。 
5. 排序，丢弃重复的，流量控制。

##### 伪首部的作用

用于计算校验和，包含IP信息，避免目的端错误地接收错误路由的数据报。

检查数据是否已经正确的到达目的地。

##### 三次握手，四次挥手

###### 三次握手

- 客户端–发送带有 SYN 标志的数据包–一次握手–服务端
- 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端
- 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端

###### 为什么需要？

1. **三次握手的目的是建立可靠的通信信道，三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

2. 防止已过期的连接请求报文突然又传送到服务器，因而产生错误

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

###### 四次挥手：

- 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
- 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加 1 。和 SYN 一样，一个 FIN 将占用一个序号
- 服务器-关闭与客户端的连接，发送一个 FIN 给客户端
- 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加 1
- 客户端等待2MSL后么关闭连接。

##### 为什么客户端在第四次挥手后还会等待2MSL?

等待2MSL是为了保证服务端接收到了ACK报文，因为ACk报文可能会丢失，如果服务端没接收到ACK报文的话，会重新发送FIN报文，只有当客户端等待了2MSL都没有收到重新发送的FIN报文时，才表示服务端是正常接收到了ACK报文，这个时候客户端就能关闭了。

##### TCP拥塞控制机制

- 慢开始
- 拥塞避免
- 快重传
- 快恢复

![image-20220713134137603](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220713134137603.png)

![image-20220713134151627](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220713134151627.png)

##### HTTP协议与HTTPS协议基本概念

全称超文本传输协议，主要用于B/S模型，是来规范浏览器和服务器端的行为的

HTTPS 协议，是 HTTP 的加强安全版本，解决HTTP数据透明的问题。HTTPS 是基于 HTTP 的，也是用 TCP 作为底层协议，并额外使用 SSL/TLS 协议用作加密和安全认证。默认端口号是 443.

##### HTTP1.0与HTTP1.1的优化

- 新增许多相应状态码
- 采用了长连接 减少资源浪费
- 范围请求 即为了避免带宽浪费，客户端值请求文件的一部分内容，可以在请求中加入Range头部，以请求数据的一部分 **如果一个响应包含部分数据，则返回206状态码以区别于完整数据**
- 缓存处理，引入了更多的缓存控制策略
- 请求头增加了Host字段

##### 浏览器输入一个URL 显示主页的过程

1. 浏览器查找域名的IP地址
2. 浏览器向web服务器发送HTTP请求
3. 服务器处理请求，返回响应
4. 浏览器渲染服务器发回的响应

获取域名：DNS

发送HTTP请求 ： HTTP TCP IP OSPF ARP

##### HTTP2.0 与1.1的区别

![image-20220713134427468](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220713134427468.png)

##### DNS：

![image-20220713134615029](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220713134615029.png)

##### GET与POST区别

GET请求主要是主要是通过URI来作为资源的标识，来请求服务器发送特定的资源。

而post主要是向服务器发送数据，进行操作。

![image-20220713134655191](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220713134655191.png)

##### Cookies与Session的区别：

Cookies:服务器发送到用户浏览器并保存在客户端本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带送到服务器上。Cookies有http规范约束，只能通过http头设置与传输，使基于无状态的HTTP协议记录稳定的状态信息成为了可能。

Session:指的是服务器上为每个客户端所开辟的独立存储空间，在其中保存的信息就是用于保存状态的。利用cookies进行信息处理

1. cookie更多的用于认识用户行为。比如这台计算机的用户访问了哪些页面
   session则更多的用于识别用户本身。
2. c存放在浏览器，s存放于服务器，s更加安全
3. cookie有会话cookie和持久cookie，生命周期为浏览器会话期的会话cookie保存在缓存，关闭浏览器窗口就消失；持久cookie被保存在硬盘，直到超过设定的过期时间

### 数据结构

#### 树

树是一种非线性数据结构，也是一种特殊的图，它由一组空或者非空节点的集合以及结点的关系组成，其中有一个不被任何结点指向的结点称为根节点，其余结点分为若干个互不相交的子集，被根节点指向，称为子树。

##### 一棵树具有以下特点：

1. 一棵树中的任意两个结点有且仅有唯一的一条路径连通。
2. 一棵树如果有 n 个结点，那么它一定恰好有 n-1 条边。
3. 一棵树不包含回路。

#### 二叉树

**二叉树**是每个节点最多只有两个分支（即不存在分支度大于 2 的节点）的树结构。且这两个分支有先后顺序，被称为左右子树

##### 完全二叉树：

除最后一层外，若其余层都是满的，并且最后一层或者是满的，或者是在右边缺少连续若干节点，则这个二叉树就是 **完全二叉树** 

##### 平衡二叉树

**平衡二叉树** 是一棵二叉排序树，且具有以下性质：

1. 可以是一棵空树
2. 如果不是空树，它的左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一棵平衡二叉树。

二叉树的存储方式：

- 链式存储
- 顺序存储（数组的每个位置存储结点的值，而数组的索引作为二叉树的子树位置【比如i结点的左子树和右子树为2*i,2*i+1】）

##### 二叉树的遍历

先序遍历、后序遍历、中序、层序遍历

#### 堆

堆也是一种特殊的树，分为最大堆与最小堆。对应于堆中的每一个节点值都大于等于（或小于等于）子树中所有节点的值。或者任意一个节点的值都小于等于（或小于等于）所有子节点的值。

堆的主要实现方式是用数组存储的完全二叉树

我们来写一下最小堆的实现：

```java
/**
 * 最小堆
 * 初始化后大小确定
 */
public class MinHeap {
    private int size;
    private int[] arr;

    /**
     * 建立最小堆
     * 从最后一个父节点开始（len/2），反复调用调整堆的算法
     * 为什么要从最后一个开始？ 因为保证子树已经是最小堆了，否则如果从根节点开始，那么一开始交换到根节点的值并不是最小值，之后还要交换
     * 时间复杂度 O(NlgN)
     * @param arr 初始化堆的数组
     */
    public MinHeap(int[] arr){
        for (int i = (arr.length-2)/2; i >=0 ; i--) {
            HeapAdjust(i);
        }
        size = arr.length;
    }

    public MinHeap(int size){
        this.size = 0;
        arr = new int[size];
    }

    /**
     * 往最小堆中添加一个元素
     * 当数组满时，抛出异常
     * 否则size ++ ,然后将数组放在最末尾，调整堆
     * 这个调整堆的算法必须自底向上
     * 时间复杂度 O(lgN)
     * @param e 添加的元素
     */
    public void add(int e){
        if (size == arr.length)throw new RuntimeException();
        arr[size++] = e;
        int temp = arr[size-1];
        int i;
        for (i = size-1; i > 0;) {
            int parent = (i-1)/2;
            if (temp>=arr[parent])break;
            arr[i] = arr[parent];
            i = parent;
        }
        arr[i] = temp;
    }

    /**
     * 获取最小的元素
     * 将堆最后的一个元素放到堆头，然后调整堆
     * 时间复杂度 O(lgN)
     * @return 最小的元素
     */
    public int get(){
        if (size == 0)throw new RuntimeException();
        int ans = arr[0];
        arr[0] = arr[--size];
        HeapAdjust(0);
        return ans;
    }

    /**
     * 堆调整
     * 子树已经是最小堆,或者是叶子结点了
     * @param index 根节点索引
     */
    private void HeapAdjust(int index){
        // 暂存根节点的值
        int temp = arr[index];
        // 自上而下进行调整
        for (int i = 2*index+1; i <= size-1; i = i*2+1) {
            // 这一步选出最小值在左子树还是右子树
            if (arr[i]>arr[i+1]){
                i++;
            }
            //如果根节点的值已经是最小的了，已经调整完毕
            if (temp<=arr[i])break;
            //否则 将子树的值调整到父节点
            arr[index] = arr[i];
            // index 指向子树的根 继续调整(注意此时子树根的值还是旧值，按理说应该更新temp的值，但是可以放到最后更新)
            index = i;
        }
        // 把根节点的值放到最后的位置，完成调整。
        arr[index] = temp;
    }
}
```

#### 图

图是由顶点集合以及边集合组成的非线性的数据结构。分为有向图与无向图（边是否具有方向性）

##### 图的存储方式

- 邻接矩阵
- 邻接表

#### 最小生成树

对于有n个结点的连通图，去掉原图中的一些边，生成原图的最小连通子图，它包含原图的所有结点，且保持连通的最少边，此时，图就是一颗树

##### Prime算法：

任意选择一个根节点，然后每次选择一个与它距离最近的结点加入子集，循环操作，直到所有结点都加入

##### 克鲁斯卡尔算法：

先建立一个有n个根节点的森林，每次选择一条最短的边，如果加入这条边不会产生回路，则加入，重复知道加入了n-1条边

#### 最短路径算法(第几斯特拉算法)：

求解一个图中一个点到其余各点的最短路径。

限制条件：边的权重不能是负数。

##### 算法思想：

基于贪心算法实现。

时间复杂度 O（n*n）

初始情况下，结果集包含初始结点k，他到各结点的距离为直接连接的距离

对于n-1个结点，以下步骤循环n-1次：

1. 从距离集中选出最小的结点k1加入结果集，并打印路径
2. 更新到其余各点的距离，如果到其他结点的距离通过k1能够更短，根据距离以及路径

##### 弗洛伊德算法：

时间复杂度 O（n3）

他的主要思想是递推更新一个n阶方阵A，A描述各个结点之间的距离，通过不断加入中间结点，更新距离。需要递推n次。

它的优点是可以允许权重是负值

#### AVL树：

**先介绍二叉搜索树的概念：**

对于一颗二叉搜索树，其根节点的左子树的值都小于它，右子树的值都大于他，且不允许重复值。

利用二叉搜索树可以快速进行查找元素，但是不平衡的二叉树会降低效率。

##### 平衡二叉树

是一种改进的二叉搜索树，在AVL树中，任意子树的左子树和右子树的高度差不能超过1

#### 红黑树

AVL树调整操作的时间复杂度是比较高的，所以红黑树是一种折中的方案，它是保持黑平衡的二叉搜索树。搜索略慢于AVL树，而添加删除元素则更快。从性能来说，红黑树比AVL树更好。

##### 红黑树概念：

- 每个结点有一个颜色属性，要么是红色，要么是黑色
- 根节点是黑色，且虚构的叶节点也是黑色
- 不存在两个相邻的红色结点
- 对每个结点，从该结点到任一叶节点包含的黑结点数量相等。

#### B树

是一种多路平衡查找树，其出现是为了满足数据库对磁盘读写次数的需要

B树的阶是指B树中单节点最大的孩子结点个数

B树的查找到元素的次数对应于磁盘存取的次数

m叉树的特点：

- 每个结点最多有m个子树，最多有m-1个关键字

- 根节点如果不是终端结点，则至少有2颗子树

- 所有的终端结点位于同一层，且不带信息

- 对于一个非叶子结点，它由关键字和指向孩子结点的指针组成，孩子结点的所有关键字大小范围由指针两侧的关键字决定

#### B+树：

是应数据库所需而出现的一种B树的变形，目的是为了减少树的高度，从而减少磁盘的IO

不同于B树的特点：

- 结点子树个数与关键字个数相等
- 叶节点包含全部关键字，以及指向记录的指针，且是有序的并被链表链接起来
- 分支节点关键字有序，且包含指向孩子结点的指针，分支节点的关键字只记录孩子结点中的最大值
- 分支节点只起到索引的作用

两者区别：1. B+树只有叶子结点带有指向数据指针，而B树则都有，且索引不会重复。2. B+树的所有数据构成一个有序链表

#### 排序算法

##### 稳定排序与非稳定排序的区别：

稳定排序：对于两个相等的数据，排序前后其相对位置不会发生变化

非稳定排序：两个相等得数据，排序前后相对位置改变了

##### 常见稳定排序：

插入排序、冒泡排序、归并排序、基数排序

##### 常见不稳定排序：

希尔排序、快速排序、堆排序、直接选择排序

#### KMP算法：

KMP算法用于快速在一个字符串中寻找另一个子串。

他对于暴力匹配算法的改进之处在于每次匹配失败后，主串不会回溯，而子串会回溯到特定的位置，重新开始匹配，从而省去了很多不必要的回溯。

为什么可以这么做呢？因为在暴力匹配时，如果匹配失败，并不代表两个模式是完全不一样的，而是仅有失败那一位不同，所以我们可以找当前子串的最长前缀与后缀相等长度，然后将其回溯到前缀的后一位，继续进行匹配

那么关键就是构建子串每一位的回溯位置（这个位置只与子串有关），这就是KMP的改进之处

```java
    public static int kmp(String s,String p){
        if (p.length()==0)
            return 0;
        if (p.length() == 1){
            return s.indexOf(p.charAt(0));
        }
        // 先构建出next数组
        // 动态规划的思想
        int[] next = new int[p.length()];
        next[0] = -1;
        next[1] = 0;
        // j代表后缀的最后一个元素的下标
        // k代表前缀最后一个元素的下标
        int j = 1; 
        int k = 0; 
        while(j<p.length()-1){
            if(k == -1 || p.charAt(k) == p.charAt(j)){ // 第k个元素与第j个元素相等
                next[++j] = ++k;
            }
            else{
                // 不匹配 那么就要回溯到之前求出来的最长匹配长度的位置
                k = next[k];

            }
        }
        // KMP
        int n = s.length();
        int m = p.length();
        int i = 0;
        j = 0;
        while(i<n && j<m){
            if (j == -1 || s.charAt(i) == p.charAt(j)){
                i++;j++;
            }
            else{
                j = next[j];

            }
        }
        if (j == m){
            return i-m;
        }
        else{
            return -1;
        }
    }
```

### 数据库

#### 术语

**属性（attribute）**：列的名字

**依赖（relation）**：列属性间存在的某种联系。 完全函数依赖、部分函数依赖、传递函数依赖

**元组（tuple）**：每一个行

**表（table）**：由多个属性，以及众多元组所表示的各个实例组成。

**键（key）**：由关系的一个或多个属性组成，任意两个键相同的元组，所有属性都相同。

**候选键（candidate key）**：由关系的一个或多个属性组成，候选键都具备键的特征，都有资格成为主键。

**外键（foreign key）**：如果某一个关系A中的一个（组）属性是另一个关系B的键，则该（组）属性在A中称为外键。

**主属性（prime attribute）**：所有候选键所包含的属性都是主属性。

**自然连接（natural join）**：第一个关系中每一行与第二个关系的每一行进行匹配，如果得到有交叉部分则合并，若无交叉部分则舍弃。

**连接（theta join）**：即加上约束条件的笛卡儿积，先得到笛卡儿积，然后根据约束条件删除不满足的元组。

**除法运算（division）**：关系R除以关系S的结果为T，则T包含所有在R但不在S中的属性，且T的元组与S的元组的所有组合在R中。

#### 数据库范式

设计不规范的表不仅会有冗余，而且因为存在部分函数依赖，在插入数据与删除数据时会发生异常

- 第一范式 属性都是不可分的
- 第二范式 消除非主属性对主属性的部分函数依赖
- 第三范式 消除非主属性对主属性的传递函数依赖

#### E-R图

Entity-Relationship，有三个组成部分: 实体、属性、联系。

用来进行关系型数据库系统的概念设计。

##### 实体的三种联系

包含一对一，一对多，多对多三种。

- 如果 A 到 B 是一对多关系，那么画个带箭头的线段指向 B；
- 如果是一对一，画两个带箭头的线段；
- 如果是多对多，画两个不带箭头的线段。

#### 数据库的索引类别

##### B+树索引

由B+树构成的索引，树高较小，所以磁盘读写次数较少，只有叶子结点的索引存有指向数据的指针，非叶子结点的数据只起到索引的作用（只存放孩子结点的最大值）并且数据构成有序链表，方便范围查找。

##### 哈希索引

由哈希表构成的索引，哈希索引能以 O(1) 时间进行查找，但是失去了有序性，它具有以下限制:

- 无法用于排序与分组；
- 只支持精确查找，无法用于部分查找和范围查找。

##### 全文索引

由倒排索引实现，支持查找文本中的关键词是否匹配，一般用于信息检索。

##### 索引的优点

大大减少了服务器需要扫描的数据行数

有利于进行范围查找，减少了数据库查询时的分组与排序操作（因为本身就是有序的）

对于有序的索引，可以将相邻的数据存储在一起，这样就可以优化IO

- 对于非常小的表，可能全表扫描会快一点
- 对于中到大型的表，索引是十分高效的
- 对于特大型的表，创建于维护索引的代价也比价大，最好采用分区技术进行查询

#### 事务四大特性？

- 原子性(**Atomicity**)：事务是一个不可再分割的工作单元，事务中的操作要么都发生，要么都不发生。(undo log)
- 隔离性(**Isolation**)：多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。(mvcc 锁)
- 一致性(**Consistency**)：数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性，一致性需要原子性与隔离性的保证，与这两者不是对等的关系。
- 持久性(**Durability**)：在事务完成以后，该事务所对数据库所做的更改便持久的保存在数据库之中，并不会被回滚。（redo log）

#### 数据库的事务隔离级别的实现：

##### 加悲观锁

- 排它锁：写锁，加了之后对于数据或表不能被其他事务访问，独占锁获取后必须在事务结束时释放
- 共享锁： 读锁，加了之后能继续加读锁，但是不能加写锁
- 意向锁：如果只用写锁与读锁，由于锁的粒度有很多种，那么加锁前，检查锁可能是一个很耗时的操作，由此引入意向锁，是一个表级别的锁
  - 一个事务在获得某个数据行对象的写锁锁之前，必须先获得表的 IS 锁或者更强的锁
  - 一个事务在获得某个数据行对象的读锁之前，必须先获得表的 IX 锁

##### MVCC

MVCC通过undoLog实现，能解决数据库的脏读、不可重复读问题。他由于没有真正加锁，并发度会更高。Mysql使用MVCC来实现RC、RR

表中每一行都有两个隐藏字段，trxId和roll_pointer分别指向当前修改数据的事务号以及该数据的undo log链表（每次对数据的修改都会增加一个undolog 删除操作是设置删除标志位，这样历史数据就传成了一个链表），（事务号不会重复，递增）

readView 数据快照，读取数据从快照中读取，不会加锁

当前读：每次都是读取的最新的数据（会加读锁）。

###### MVCC的实现方式：

生成readView，这个`ReadView`中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务id放到一个列表中，我们把这个列表命名为为`m_ids`

- 如果被访问版本的`trx_id`属性值小于`m_ids`列表中最小的事务id，表明生成该版本的事务在生成`ReadView`前已经提交，所以该版本可以被当前事务访问。

- 如果被访问版本的`trx_id`属性值大于`max_trx_id`(下次给事务分配的id)，表明生成该版本的事务在生成`ReadView`后才生成，所以该版本不可以被当前事务访问。

- 如果被访问版本的`trx_id`属性值在`m_ids`列表中最大的事务id和最小事务id之间，那就需要判断一下`trx_id`属性值是不是在`m_ids`列表中，如果在，说明创建`ReadView`时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建`ReadView`时生成该版本的事务已经被提交，该版本可以被访问。

对于读已提交，每次select都会生成一个readView

对于可重复读，只有第一次select会生成readView

但是MVCC无法解决幻读问题，对于幻读问题，必须要加锁才能完成

#### 数据库发展历史

数据库发展最初过程中，诞生过3种数据模型，最终关系型模型成为了应用最为广泛的数据库模型。

- 网状模型：用有向图表示实体和实体之间的联系的数据结构模型称为网状数据模型。

- 层次模型：层次数据模型是用树状<层次>结构来组织数据的数据模型。

- 关系模型：使用表格表示实体和实体之间关系的数据模型称之为关系数据模型。

|     | 网状模型                 | 层次模型                                        | 关系模型                                            |
| --- | -------------------- | ------------------------------------------- | ----------------------------------------------- |
| 优势  | 能直接描述现实世界 存取效率较高     | 结构简单 查询效率高 可以提供较好的完整性支持                     | 实体及实体间的的联系都通过二维表结构表示 可以方便的表示 M:N 关系 数据访问路径对用户透明 |
| 劣势  | 结构复杂 用户不易使用 访问程序设计复杂 | 无法表示 M:N 的关系 插入、删除限制多 遍历子节点必须经过父节点 访问程序设计复杂 | 关联查询效率不够高 关系必须规范化                               |

#### MYSQL 的 SQL 执行流程

1. 连接到数据库
2. 检查验证信息与权限是否正确
3. 分配线程处理查询
4. SQL引擎解析、重写、优化、执行SQL引擎
5. SQL引擎与存储引擎交互进行对数据库的操作

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/076973e4b378447dafa4f75caa1b0b35~tplv-k3u1fbpfcp-zoom-in-crop-mark:1304:0:0:0.awebp)

#### SQL 引擎

- Paser：经过词法分析、语法分析生成语法树，然后对语法树进行合法性校验。

- Optimizer：根据 Parser 产生的语法树，根据规则或者代价产生执行计划树。

- Executor：根据计划树进行执行，常见的执行方式是火山模型。

#### 存储引擎

存储引擎负责了数据的底层存储、管理和访问工作。MySQL 的 InnoDB 存储引擎：

- Buffer Pool：存储引擎位于内存中的重要结构，用于缓存数据，减少磁盘 IO 的开销。
- Page：数据存储的最基本单位，一般为 16KB。

#### 事务引擎

事务引擎实现了数据库的 ACID 能力，这里还是以 MySQL 的 InnoDB 为例来介绍数据库内部是通过哪些技术来实现 ACID：

- Atomicity：InnoDB 中通过 undo 日志实现了数据库的原子性，通过 Undo Log，数据库可以回滚到事务开始的状态；

- Isolation：通过 Undo Log 实现 MVCC（多版本并发控制），降低读写冲突。

- Durability：通过 Redo Log（一种 WAL 实现方式）来保证事务在提交后一定能持久化到磁盘中。

- Consistency：一致性本质上是一种业务层的限制。

#### sql语句执行顺序？

![image-20220614200645037](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220614200645037.png)

#### sql语句优化相关

##### 表连接

- 内连接：对于内连接的两个表，若驱动表中的记录在被驱动表中找不到匹配的记录，就`不加入到最终的结果集`
- 外连接：即使被驱动表中没有匹配的记录，也加入最终结果集
- 左外连接：选取左表为驱动表（右连接则相反）

索引

索引是存储在一张表中特定列上的数据结构，索引是在列上创建的。

在 MySQL 中，主要有下面这几种索引实现方式：

- 哈希索引(HASH)：哈希索引是 MySQL 中用到的唯一 key-value 键值对的数据结构，很适合作为索引。HASH 索引具有一次定位的好处，不需要像树那样逐个节点查找，但是这种查找适合应用于查找单个键的情况，对于范围查找，HASH 索引的性能就会很低。
- B-Tree 索引：B 就是 Balance 的意思，BTree 是一种平衡树，它有很多变种，最常见的就是 B+ Tree，它被 MySQL 广泛使用。
- R-Tree 索引：R-Tree 在 MySQL 很少使用，仅支持 geometry 数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种，相对于 B-Tree 来说，R-Tree 的优势在于范围查找。

##### sql优化

- 查询语句无论是使用哪种判断条件 **等于、小于、大于**， `WHERE` 左侧的条件查询字段不要使用函数或者表达式

- 当你的 SELECT 查询语句只需要使用一条记录时，要使用 `LIMIT 1`

- 不要直接使用 `SELECT *`，而应该使用具体需要查询的表字段。

- 为每一张表设置一个 ID 属性

- 避免在 `WHERE` 字句中对字段进行 `NULL` 判断

- 避免在 `WHERE` 中使用 `!=` 或 `<>` 操作符

- 使用 `BETWEEN AND` 替代 `IN`

- 为搜索字段创建索引

- 使用 `LIKE %abc%` 不会走索引，而使用 `LIKE abc%` 会走索引

- 对于枚举类型的字段(即有固定罗列值的字段)，建议使用`ENUM`而不是`VARCHAR`，如性别、星期、类型、类别等

- 拆分大的 DELETE 或 INSERT 语句

- 选择合适的字段类型，选择标准是 **尽可能小、尽可能定长、尽可能使用整数**。

- 字段设计尽可能使用 `NOT NULL`

#### Mysql存储引擎

mysql最近的版本都是使用事务存储引擎InnoDB,之前使用自己自带的MYISAM

##### InnoDB与MYISAM区别

- 支持事务，支持外键
- 支持更小粒度的锁
- 主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘
- 崩溃恢复做的更好
- MyIsam在性能上要更好

### Redis

#### 什么是redis？

Redis是一款内存高速缓存数据库。支持以key-value的形式来存储数据，并且有多种高效的数据结构来满足不同的数据类型。Redis可以用于缓存、发布订阅模型、分布式锁、高速队列等场景，并且支持持久化。

#### 基本数据类型：

key都是字符串，value有多种数据类型

- String （sds）
- list 列表（ziplist/quicklist/双向链表）
- 无序集合(intset ziplist)
- 有序集合（跳表+哈希表）
- 哈希表 内部元素都是k-v键值对(ziplist/hashtable)
- bitmap 操作位，适合于统计用户一年来的登陆情况等。一位就表示一个数据情况（0 1）
- hyperLogLogs 基数统计，每个键占的内存大小是一样的 ，适合于统计如网站在线人数、访问量等信息（是允许误差的），消耗的内存空间会小很多。
- Stream 是redis实现的支持多播的可持久化的消息队列，借鉴了卡夫卡的设计理念，有生产者、消费者组等概念。

#### Redis的数据结构

redis的命令通常都是对key进行操作，但是value的数据结构有很多种，我们必须先知道对于的数据结构，才能执行具体的操作

每个redis的key都会带有value的类型信息，称为redisObject，通过它来找到底层的数据结构

redis底层的数据结构如下：

##### SDS：(String)

redis存储字符串的结构。

redis没有使用c语言的原生字符串，而是自己设计的。其有三部分组成：头部+数据+'\0'

SDS可以在常数时间内获取字符串长度、不会发生缓存区溢出的现象（动态扩容）并且对二进制安全，原生字符串有这些问题，而SDS解决了

##### ZIPLIST（List）

为了提高存储效率而设计的一种特殊编码的双向链表(主要是链表不是连续内存，无法利用局部性原理；而数组每个元素长度固定，会造成浪费)。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在O(1)的时间复杂度下完成list两端的push和pop操作。

![image-20220827145517282](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220827145517282.png)

entry用于存储数据，并且还保存了上一个元素的长度，当前entry的类型与长度，在entry内存不足时会扩容

缺点：

- ziplist也不预留内存空间, 并且在移除结点后, 也是立即缩容, 这代表每次写操作都会进行内存分配操作.- 

- 结点如果扩容, 导致结点占用的内存增长, 并且超过254字节的话, 可能会导致链式反应: 

##### QuickList

是一种以ziplist为结点的双端链表结构. 宏观上, quicklist是一个链表, 微观上, 链表中的每个结点都是一个ziplist。是对压缩列表的改进

在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。

##### Hash

就是链地址法解决哈希冲突的散列表

**渐近式 rehash**

什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。

##### IntSet 整数集合

是实现只包含整数元素的set的数据结构

结构：

![image-20220827151254455](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220827151254455.png)

扩容：如果新增一个Int32的整数在int16，那么对每个元素都要扩容，但是不会缩容

##### SkipList（Zset）

跳表,是为了快速查找有序链表中的某一个数据，是多层有序链表。

主要思想就是类似于多级索引，加快查找速度。

#### 持久化

##### RDB

RDB持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值。

触发方式：自动触发（一定时间 间隔、关闭数据库、主从复制等） 手动触发（save bgsave）

RDB优缺点

- **优点**
  - RDB文件是某个时间节点的快照，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景；
  - Redis加载RDB文件恢复数据要远远快于AOF方式；
- **缺点**
  - RDB方式实时性不够，无法做到秒级的持久化（过于频繁的RDB会消耗大量资源）；
  - 每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高；

##### AOF

AOF日志记录Redis的每个写命令，步骤分为：命令追加（append）、文件写入（write）和文件同步（sync）。

关于何时将缓存中的日记记录回AOF文件，有三种策略：

`Always`，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；

`Everysec`，每秒写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；

`No`，操作系统控制的写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

AOF重写

AOF会记录每个写命令到AOF文件，随着时间越来越长，AOF文件会变得越来越大。如果不加以控制，会对Redis服务器，甚至对操作系统造成影响，而且AOF文件越大，数据恢复也越慢。为了解决AOF文件体积膨胀的问题，Redis提供AOF文件重写机制来对AOF文件进行“瘦身”。（多个操作可以合并为一个操作）

##### 两者混合使用

redis4.0后可以使用这种模式，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。这样快照的执行间隔可以不用太短，同时aop文件大小也不会太大。注意，第二次快照时会清除aof数据

**备份的一个重要性能影响因素：fork进程进行备份操作**

#### 发布-订阅模型

Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。

Redis 的 SUBSCRIBE 命令可以让客户端订阅任意数量的频道， 每当有新信息发送到被订阅的频道时， 信息就会被发送给所有订阅指定频道的客户端。

#### 理解Redis的IO多路复用

这里需要先说一下IO多路复用模型的Reactor模式（如上文所说）

而redis对应网络请求的处理就是基于IO多路复用模型Reactor模式，自己开发了自己的网络事件处理器，称为文件事件处理器，他同时监听多个套接字，当套接字出现网络请求时，会调用响应时间的处理函数进行处理。

Redis 的单线程主要是指 Redis 的网络 IO 和键值对读写事件处理是由一个线程来完成的。

redis的文件事件处理器由套接字、IO多路复用程序、文件事件分排器、文件事件处理器组成。

当IO多路复用程序监听到有套接字有网络请求时，将产生事件的套接字放在一个就绪文件队列里面，而文件分派器就从队列中有序的获取，然后分发对应的处理器进行处理

所以，一次 Redis 客户端与服务器进行连接并且发送命令的过程如下：

- 客户端向服务端发起**建立 socket 连接的请求**，那么监听套接字将产生 AE_READABLE 事件，触发连接应答处理器执行。处理器会对客户端的连接请求
- 进行**应答**，然后创建客户端套接字，以及客户端状态，并将客户端套接字的 AE_READABLE 事件与命令请求处理器关联。
- 客户端建立连接后，向服务器**发送命令**，那么客户端套接字将产生 AE_READABLE 事件，触发命令请求处理器执行，处理器读取客户端命令，然后传递给相关程序去执行。
- **执行命令获得相应的命令回复**，为了将命令回复传递给客户端，服务器将客户端套接字的 AE_WRITEABLE 事件与命令回复处理器关联。当客户端试图读取命令回复时，客户端套接字产生 AE_WRITEABLE 事件，触发命令回复处理器将命令回复全部写入到套接字中。

#### Redis事务

Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。

MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。

EXEC：执行事务中的所有操作命令。

DISCARD：取消事务，放弃执行事务块中的所有命令。

WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。

UNWATCH：取消WATCH对所有key的监视。

注意 redis中的事务，如果是命令编译报错，则所有命令都不会执行，而如果是执行过程中报错，只有那条命令不会执行

##### watch

是一种乐观锁，在事务前开启watch指定的keys，如果值发生了变化，则整个事务不会执行

#### 主从复制

为了避免单点故障，所以会将一台服务器上的数据，备份到多台服务器上，以提高可用性

主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。

主从库之间采用的是**读写分离**的方式，提高性能；

- 读操作：主库、从库都可以接收；
- 写操作：首先到主库执行，然后，主库将写操作同步给从库。

![image-20220827170215230](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220827170215230.png)

- 全量复制 一次性将所有数据都发送给从库
- 增量复制 只发送距离上一次复制操作之后，有变化的数据。

#### 哨兵机制

主从复制模式下，如果主节点出现故障宕机了，那么该怎么办呢？

在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的问题。

`sentinel monitor lbwnb 127.0.0.1 6001 1` 表示是哨兵节点，最后一个参数代表多少个哨兵认为主节点下线才会进行选举

选举标准：

1. 首先会根据优先级进行选择，可以在配置文件中进行配置，添加`replica-priority`配置项（默认是100），越小表示优先级越高。

2. 如果优先级一样，那就选择偏移量最大的(代表数据一致性最高)

3. 要是还选不出来，那就选择runid（启动时随机生成的）最小的。

*使用哨兵模式后，java客户端对redis的访问通过哨兵来配置。*

#### redis集群

一台redis服务器不够存储所有数据，那么就可以把这些数据存放到多个redis数据库中，构建一个redis集群，集群结点间的通讯通过集群总线

![image-20220807205023296](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220807205023296.png)

一个Redis集群包含16384个插槽，集群中的每个Redis 实例负责维护一部分插槽以及插槽所映射的键值数据。

实际上，插槽就是键的Hash计算后的一个结果，注意这里出现了`计算机网络`中的CRC循环冗余校验，这里采用CRC16，能得到16个bit位的数据，也就是说算出来之后结果是0-65535之间，再进行取模，得到最终结果：

**Redis key的路由计算公式：slot = CRC16（key） % 16384**

结果的值是多少，就应该存放到对应维护的Redis下，比如Redis节点1负责0-25565的插槽，而这时客户端插入了一个新的数据`a=10`，a在Hash计算后结果为666，那么a就应该存放到1号Redis节点中。简而言之，本质上就是通过哈希算法将插入的数据分摊到各个节点的。

**如果集群中某个主结点挂掉了，那么从节点会被选取出来成为主节点，如果没有任何从节点了，那么集群就不可用了。**

#### Redis缓存问题

缓存穿透：某个数据过期，而对这个数据的读取很频繁。

1. 热点数据永不过期
2. 做好服务的限流、降级与熔断

缓存击穿：缓存与数据库中都没有数据 ，可能是一种恶意攻击。解决：拦截、找不到的数据设置一个空值

缓存雪崩：大批量的数据过期，此时来了一堆对其的读请求

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。
3. 设置热点数据永远不过期。

缓存污染： 指很多数据只是用几次就不用了，但是一直存在于缓存中

#### redis数据删除策略

在单机版Redis中，存在两种删除策略：

- `惰性删除`：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。
- `定期删除`：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。

#### 缓存淘汰策略

如果redis的缓存满了，这时再插入数据，会触发不同的淘汰策略（主要目的是淘汰不需要使用的数据）。

- 不淘汰
- 对设置了过期时间的数据按照一定策略淘汰
- 对所有数据按照一定策略淘汰

#### 数据库与缓存的一致性

数据库与缓存的一致性问题在很多情况下都会存在，发生于有写操作的情况下

**不管是先写MySQL数据库，再删除Redis缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况**。举一个例子：

1.如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。

2.如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。

因为写和读是并发的，没法保证顺序,就会出现缓存和数据库的数据不一致的问题。

最常见的策略是读先读缓存，没有读数据库，设置缓存，写先修改数据库，再更新缓存。

这种策略我觉得最重要的是保证写操作的更新缓存操作能够成功，不然很可能缓存中就存放的是脏数据，可以使用消息队列消费消息的机制进行重试

### git

#### 分支

分支意味着你可以把你的工作从开发主线上分离开来，以免影响开发主线。 

当你准备开发一个新功能，但是需要花很长时间才能完成，第一次你写了一部分的代码，如果立刻提交，但是代码还没写完，不完整的代码会影响到和你一起工作的其他同事伙伴的工作。如果等代码全部写完再一次提交，又有着代码丢失或者突发事件等的影响。

分支在这时候的作用就体现出来了，我们创建一个自己的分支，别人是看不到的，我们就可以在原来的基础上继续自己正常的工作，想提交就提交，直到开发结束，再来一次性合并到主分支上，即不影响他人，也保证了代码的安全。

```
git branch 分支名
git checkout -b feature_x 创建并转到
git checkout 分支名
git merge 需要合并的分支名
git push origin 将分支推送到orgin
git branch -d feature_x 删除分支
```

1. **提出更改（把它们添加到暂存区**）：`git add filename `(针对特定文件)、`git add *`(所有文件)、`git add *.txt`（支持通配符，所有 .txt 文件）

2. **忽略文件**：`.gitignore` 文件

3. **提交更新:** `git commit -m "代码提交信息"` （每次准备提交前，先用 `git status` 看下，是不是都已暂存起来了， 然后再运行提交命令 `git commit`）

4. **跳过使用暂存区域更新的方式** : `git commit -a -m "代码提交信息"`。 `git commit` 加上 `-a` 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 `git add` 步骤。

5. **移除文件** ：`git rm filename` （从暂存区域移除，然后提交。）

6. 如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：`git remote add origin <server>` ,比如我们要让本地的一个仓库和 Github 上创建的一个仓库关联可以这样`git remote add origin https://github.com/Snailclimb/test.git`

7. 将这些改动提交到远端仓库：`git push origin master` (可以把 *master* 换成你想要推送的任何分支)

8. 将 test 重命名为 test1：`git remote rename test test1`

9. 移除远程仓库 test1:`git remote rm test1`

10. 在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。 完成这个任务最简单而又有效的工具是 `git log` 命令。`git log` 会按提交时间列出所有的更新，最近的更新排在最上面。`git log --author=bob`

11. 有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 `--amend` 选项的提交命令尝试重新提交： `git commit --amend`

12. 假如你想丢弃你在本地的所有改动与提交，可以到服务器上获取最新的版本历史，并将你本地主分支指向它：

```
git fetch origin
git reset --hard origin/master
```

### 框架

#### ================================================

#### mybatis缓存机制

为了提高数据库查询效率，mybatis提供了缓存机制

##### 一级缓存

对sqlSession有效，每一个sqlSession的cahe互相隔离，并且每次更新操作、提交与回滚都会清空缓存。一级缓存非常高效，但是有一定的局限性，只能针对当前session。在spring中的话，如果不开启事务，那么每一次数据库操作都是一个SqlSession，不共用缓存。开启事务的话，则共用一级缓存。

##### 二级缓存

同一个mapper返回有效，默认关闭，需要开启。二级缓存的范围更广，但是缓存的对象必须是可序列化的。并且更新二级缓存需要sqlsession执行了提交或者关闭操作，才会进行更新。 

当存在二级缓存时，会优先从二级缓存获取数据，然后再去一级缓存，最后去数据库

当然，自带的二级缓存是无法跨服务的，同时也无法跨sqlSessionFactory，当使用分布式架构时，可以使用redis等来作为二级缓存。

#### mybatis方法重载？

mybatis是不支持方法重载的，但是有两种解决方案

1. 提供全部参数签名的方法，结合动态SQL实现 或者 使用HashMap来包裹参数，结合动态SQL实现

2. 使用jdk关键字default来实现，deault方法中定义好默认参数即可 再调用另一个方法即可。

#### ================================================

#### spring的循环依赖问题：

> 循环依赖是指bean1的成员变量依赖于bean2，bean2的成员变量又依赖于bean1，从而形成了循环依赖，对于原型模式的bean，spring会在循环依赖是直接抛出异常。对于单例模式的bean，spring使用三级列表来解决循环依赖的问题。

我们知道BeanFactory接口定义了一个IOC容器最基本的行为，这个接口的实现类都有作为容器生产、管理Bean的能力。

实际上spring使用了三层MAP的方式来处理循环依赖的问题。包括：

- singletonObjects

- earlySingletonObjects

- singletonFactories

这是三个MAP 用来存放不同时期的bean,第一个是已经注入好依赖的bean,也就是真正的容器，第二个是表示已经出现循环依赖的bean，第三个是映射创建Bean的原始工厂

以AB之间循环依赖为例说明：

- 实例化 A，此时 A 还未完成属性填充和初始化方法（@PostConstruct）的执行，A 只是一个半成品。
- 为 A 创建一个 Bean工厂，并放入到 singletonFactories 中。发现 A 需要注入 B 对象，但是一级、二级、三级缓存均未发现对象 B。
- 实例化 B，此时 B 还未完成属性填充和初始化方法（@PostConstruct）的执行，B 只是一个半成品。
- 为 B 创建一个 Bean工厂，并放入到 singletonFactories 中。
- 发现 B 需要注入 A 对象，此时在一级、二级未发现对象A，但是在三级缓存中发现了对象 A，从三级缓存中得到对象 A，并将对象 A 放入二级缓存中，同时删除三级缓存中的对象 A。（注意，此时的 A还是一个半成品，并没有完成属性填充和执行初始化方法）
- 将对象 A 注入到对象 B 中。
- 对象 B 完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 B。（此时对象 B 已经是一个成品）
- 对象 A 得到对象B，将对象 B 注入到对象 A 中。（对象 A 得到的是一个完整的对象 B）
- 对象 A完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 A。

##### 为什么需要三级缓存？

如果只使用一级缓存，那么整个流程进行中很可能会拿到还没有注入依赖的bean

而如果使用二级缓存，那么是可以线程安全的解决循环依赖问题，但是对于需要AOP生成代理对象的bean来说，必须要在后置处理时才能生成代理对象，而对于循环依赖的场景，必须要提前生成代理对象，否则会注入原始bean。所以引入三级缓存，且第三级缓存存放的是ObjectFactory。当发生循环依赖时，会调用getObject()获得bean对象或代理对象，放入二级缓存。

#### PostProcessor?

后置处理器，让我们能够插手Bean、BeanFactory、BeanDefinition的创建过程，相当于进行一个最终的处理，而最后得到的结果。

AOP机制也是通过他来实现的，因为它能改变最后生成的对象。

#### Bean生命周期：

通过扫描xml或者注解来获取bean的定义

执行Bean构造器，根据bean定义通过反射创建实例

依赖注入

回调实现了Aware接口的方法（需要bean实现），比如setBeanName setBeanFactory setBeanClassloader等

Bean后置处理器的初始化前执行方法

执行初始化方法

后置处理器的初始化后执行方法（AOP实现）

生成的bean放入一个map中

正常使用

销毁（destory方法）    

#### *refresh()方法：

作用：初始化ApplicationContext容器，完成beanFactory的创建和记载、bean的加载、以及后置处理器的注册等功能。

大致流程：

```
public void refresh() throws BeansException, IllegalStateException {
    synchronized(this.startupShutdownMonitor) {
        StartupStep contextRefresh = this.applicationStartup.start("spring.context.refresh");
        // 一些准备工作
        this.prepareRefresh();
        ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory();
          //初始化Bean工厂
        this.prepareBeanFactory(beanFactory);

        try {
            this.postProcessBeanFactory(beanFactory);
            StartupStep beanPostProcess = this.applicationStartup.start("spring.context.beans.post-process");
              //调用所有的Bean工厂、Bean定义注册后置处理器
            this.invokeBeanFactoryPostProcessors(beanFactory);
              //注册Bean后置处理器（包括Spring内部的）
            this.registerBeanPostProcessors(beanFactory);
            beanPostProcess.end();
              //国际化支持
            this.initMessageSource();
              //监听和事件广播
            this.initApplicationEventMulticaster();
            this.onRefresh();
            this.registerListeners();
              //实例化所有的Bean（懒加载除外）
            this.finishBeanFactoryInitialization(beanFactory);
            this.finishRefresh();
        } catch (BeansException var10) {
            if (this.logger.isWarnEnabled()) {
                this.logger.warn("Exception encountered during context initialization - cancelling refresh attempt: " + var10);
            }

            this.destroyBeans();
            this.cancelRefresh(var10);
            throw var10;
        } finally {
            this.resetCommonCaches();
            contextRefresh.end();
        }

    }
}
```

#### DispatcherServlet:

可以看做是一个中央servlet，对所有请求进行处理分发，然后返回响应视图。

核心方法是`doDispatch` 

大致流程：

1. 在HandlerMapping集合中寻找可以处理当前请求的HandlerMapping，没有就直接返回
2. 根据HandlerMapping提供的信息，找到可以处理的HandlerAdapter，它用于处理请求并返回ModelAndView对象，其中也包括请求参数解析、响应处理等相关处理器。
3. 最后HandlerAdapter会将结果封装为ModelAndView返回给mv
4. 执行所有拦截器的preHandle()方法（链式）
5. 用HandlerAdapter进行处理（我们编写的请求映射方法在这个位置才真正地执行了）
6. 执行所有拦截器的postHandle()方法
7. 处理结果，对mv对象进行渲染。

![image-20220731115704426](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220731115704426.png)

#### spring事务传播行为？

事务传播行为用来描述由某一个事务传播行为修饰的方法被嵌套进另一个方法的时事务如何传播。

共有7种，这里只说一下比较常用的三种

1. 在外围方法未开启事务的情况下`Propagation.REQUIRED`修饰的内部方法会新开启自己的事务，且开启的事务相互独立，互不干扰。
2. 在外围方法开启事务的情况下`Propagation.REQUIRED`修饰的内部方法会加入到外围方法的事务中，所有Propagation.REQUIRED修饰的内部方法和外围方法均属于**同一事务**，只要一个方法回滚，整个事务均回滚。
3. 在外围方法未开启事务的情况下`Propagation.REQUIRES_NEW`修饰的内部方法会新开启自己的事务，且开启的事务相互独立，互不干扰。
4. 在外围方法开启事务的情况下`Propagation.REQUIRES_NEW`修饰的内部方法事务依然独立，自己抛出的异常可以被调用方法捕捉或者全部回滚，而父方法的异常不会影响自己。（但是对同一个类中的方法调用不生效 此时与required相同）
5. 在外围方法未开启事务的情况下`Propagation.NESTED`修饰的内部方法都会新开启自己的事务，且开启的事务相互独立，互不干扰。
6. 在外围方法开启事务的情况下`Propagation.NESTED`修饰的内部方法属于外部事务的子事务，外围主事务回滚，子事务一定回滚，而内部子事务可以单独回滚（外部方法捕获异常）而不影响外围主事务和其他子事务

#### spring事务实现原理？

如果一个类或者一个类中的 public 方法上被标注`@Transactional` 注解的话，Spring 容器就会在启动的时候为其创建一个代理类，在调用被`@Transactional` 注解的 public 方法的时候，实际调用的是，`TransactionInterceptor` 类中的 `invoke()`方法。这个方法的作用就是在目标方法之前开启事务，方法执行过程中如果遇到异常的时候回滚事务，方法调用完成之后提交事务。

若同一类中的其他没有 `@Transactional` 注解的方法内部调用有 `@Transactional` 注解的方法，有`@Transactional` 注解的方法的事务会失效。这是由于`Spring AOP`代理的原因造成的，因为只有当 `@Transactional` 注解的方法在类以外被调用的时候，Spring 事务管理才生效。

#### *SpringApplication类run方法流程：

这里简单梳理一下springboot应用启动时的流程：

```
SpringApplication.run(BlogApplication.class, args);
```

```
// 这里新建了一个springApplication对象并且调用run
public static ConfigurableApplicationContext run(Class<?>[] primarySources, String[] args) {
   return new SpringApplication(primarySources).run(args);
}
```

```java
public SpringApplication(ResourceLoader resourceLoader, Class<?>... primarySources) {
   this.resourceLoader = resourceLoader;
   Assert.notNull(primarySources, "PrimarySources must not be null");
    // 主类Class赋值
   this.primarySources = new LinkedHashSet<>(Arrays.asList(primarySources));
    // 是web还是普通springboot应用
   this.webApplicationType = WebApplicationType.deduceFromClasspath();
   //创建所有ApplicationContextInitializer实现类的对象
    // 如何创建？ 扫描META-INF下的spring.factories文件，找到相关接口实现类，然后载入 一种SPI机制
    setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class));
       //创建所有ApplicationListener实现类的对象
   setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));
   this.mainApplicationClass = deduceMainApplicationClass();
}
```

```java
//Run the Spring application, creating and refreshing a new ApplicationContext.
public ConfigurableApplicationContext run(String... args) {
   StopWatch stopWatch = new StopWatch();
   stopWatch.start();
   ConfigurableApplicationContext context = null;
   configureHeadlessProperty();
   //获取所有的SpringApplicationRunListener，并通知启动事件，默认只有一个实现类EventPublishingRunListener
  //EventPublishingRunListener会将初始化各个阶段的事件转发给所有监听器
   SpringApplicationRunListeners listeners = getRunListeners(args);
   listeners.starting();
   try {
      ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
      ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments);
      configureIgnoreBeanInfo(environment);
      Banner printedBanner = printBanner(environment);
           //创建ApplicationContext，注意这里会根据是否为Web容器使用不同的ApplicationContext实现类
      context = createApplicationContext();
```

![image-20220731180852145](C:\Users\10441\AppData\Roaming\Typora\typora-user-images\image-20220731180852145.png)

可见，这个创建的容器是对spring中的注解类的容器的包装，自然也有其的功能。

```java
        //初始化ApplicationContext
        // 运行到这里，主类就被注册到容器中了
      prepareContext(context, environment, listeners, applicationArguments, printedBanner);
       // refresh容器，实际上调用的是上面说的refresh方法

      refreshContext(context);
      afterRefresh(context, applicationArguments);
      stopWatch.stop();
      if (this.logStartupInfo) {
         new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch);
      }
      listeners.started(context);
      callRunners(context, applicationArguments);
   }
   catch (Throwable ex) {
      handleRunFailure(context, ex, listeners);
      throw new IllegalStateException(ex);
   }

   try {
      listeners.running(context);
   }
   catch (Throwable ex) {
      handleRunFailure(context, ex, null);
      throw new IllegalStateException(ex);
   }
   return context;
}
```

#### springboot自动装配原理？

springboot会自动扫描外部引用 jar 包中的`META-INF/spring.factories`文件，将文件中配置的类型信息加载到 Spring 容器，并执行类中定义的各种操作。没有 Spring Boot 的情况下，如果我们需要引入第三方依赖，需要手动配置，非常麻烦。但是，Spring Boot 中，我们直接引入一个 starter 即可。引入 starter 之后，我们通过少量注解和一些简单的配置就能使用第三方组件提供的功能了。

1. Spring Boot 主类通过`@EnableAutoConfiguration`开启自动装配，因为主类是首先被注册进容器的，所以可以对主类的注解进行解析
2. 这个注解会通过@Import注解注册AutoConfigurationImportSelector类
3. 该类实现了实现了 `DeferredImportSelector`接口，也就实现了这个接口中的 `selectImports`方法，该方法主要用于**获取所有符合条件的配置类的全限定类名，这些类需要被加载到 IoC 容器中**。
4. 通过配置类装配需要用到的bean
